{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Non-Linear Regression Models - Supervised Learning\n",
    "\n",
    "- K Nearest Neighbors\n",
    "\n",
    "- Support Vector \n",
    "\n",
    "- CART (Classification and Regression)\n",
    "\n",
    "- Random Forest\n",
    "\n",
    "- Gradient Boosting Machines\n",
    "\n",
    "- XGBoost\n",
    "\n",
    "- Light GBM\n",
    "\n",
    "- CatBoost (Categorical Boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) K-Nearest Neighbors Algorithm\n",
    "\n",
    "A supervised machine learning algorithm (as opposed to an unsupervised machine learning algorithm) is one that relies on labeled input data to learn a function that produces an appropriate output when given new unlabeled data.\n",
    "\n",
    "KNN works by finding the distances between a query and all the examples in the data, selecting the specified number examples (K) closest to the query, then votes for the most frequent label (in the case of classification) or averages the labels (in the case of regression).\n",
    "\n",
    "\n",
    "![image.png](https://miro.medium.com/max/1222/1*wW8O-0xVQUFhBGexx2B6hg.png)\n",
    "\n",
    "**Source:**\n",
    "\n",
    "[Towards Data Science](https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761#:~:text=KNN%20works%20by%20finding%20the,in%20the%20case%20of%20regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T20:10:52.862750Z",
     "iopub.status.busy": "2021-10-16T20:10:52.862162Z",
     "iopub.status.idle": "2021-10-16T20:10:53.727284Z",
     "shell.execute_reply": "2021-10-16T20:10:53.726549Z",
     "shell.execute_reply.started": "2021-10-16T20:10:52.862712Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import neighbors\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:15:56.627858Z",
     "iopub.status.busy": "2021-10-16T17:15:56.627556Z",
     "iopub.status.idle": "2021-10-16T17:15:56.675866Z",
     "shell.execute_reply": "2021-10-16T17:15:56.675236Z",
     "shell.execute_reply.started": "2021-10-16T17:15:56.627822Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/hitters-baseball-data/Hitters.csv\")\n",
    "df = df.dropna()\n",
    "# Transforming categorical data to dummy data\n",
    "dms = pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])\n",
    "y = df[\"Salary\"]\n",
    "X_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis= 1).astype(\"float64\")\n",
    "X = pd.concat([X_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "y,\n",
    "test_size = 0.2,\n",
    "random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:15:56.677355Z",
     "iopub.status.busy": "2021-10-16T17:15:56.677104Z",
     "iopub.status.idle": "2021-10-16T17:15:56.710349Z",
     "shell.execute_reply": "2021-10-16T17:15:56.709605Z",
     "shell.execute_reply.started": "2021-10-16T17:15:56.677321Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>League_N</th>\n",
       "      <th>Division_W</th>\n",
       "      <th>NewLeague_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>547.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>299.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>584.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>381.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3015.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>255.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6311.0</td>\n",
       "      <td>1661.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>820.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AtBat   Hits  HmRun  Runs   RBI  Walks  Years  CAtBat   CHits  CHmRun  \\\n",
       "226  547.0  137.0    2.0  58.0  47.0   12.0    2.0  1038.0   271.0     3.0   \n",
       "220  299.0   75.0    6.0  38.0  23.0   26.0    3.0   580.0   160.0     8.0   \n",
       "128  584.0  158.0   15.0  70.0  84.0   42.0    5.0  2358.0   636.0    58.0   \n",
       "222  381.0  110.0    9.0  61.0  45.0   32.0    7.0  3015.0   834.0    40.0   \n",
       "81   255.0   70.0    7.0  49.0  35.0   43.0   15.0  6311.0  1661.0   154.0   \n",
       "\n",
       "      CRuns   CRBI  CWalks  PutOuts  Assists  Errors  League_N  Division_W  \\\n",
       "226   129.0   80.0    24.0    261.0    459.0    22.0         0           1   \n",
       "220    71.0   33.0    44.0    212.0      1.0     2.0         1           0   \n",
       "128   265.0  316.0   134.0    331.0     20.0     4.0         1           0   \n",
       "222   451.0  249.0   168.0    228.0      7.0     5.0         1           0   \n",
       "81   1019.0  608.0   820.0     51.0     54.0     8.0         1           0   \n",
       "\n",
       "     NewLeague_N  \n",
       "226            0  \n",
       "220            1  \n",
       "128            1  \n",
       "222            1  \n",
       "81             1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:15:56.712803Z",
     "iopub.status.busy": "2021-10-16T17:15:56.712520Z",
     "iopub.status.idle": "2021-10-16T17:15:56.719706Z",
     "shell.execute_reply": "2021-10-16T17:15:56.718952Z",
     "shell.execute_reply.started": "2021-10-16T17:15:56.712771Z"
    }
   },
   "outputs": [],
   "source": [
    "knn_model = KNeighborsRegressor().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:15:56.721737Z",
     "iopub.status.busy": "2021-10-16T17:15:56.720858Z",
     "iopub.status.idle": "2021-10-16T17:15:56.732239Z",
     "shell.execute_reply": "2021-10-16T17:15:56.731433Z",
     "shell.execute_reply.started": "2021-10-16T17:15:56.721700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automatically the model assign k value as 5\n",
    "# We will check the k value optimisation later\n",
    "knn_model.n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:15:56.734153Z",
     "iopub.status.busy": "2021-10-16T17:15:56.733328Z",
     "iopub.status.idle": "2021-10-16T17:15:56.741886Z",
     "shell.execute_reply": "2021-10-16T17:15:56.740969Z",
     "shell.execute_reply.started": "2021-10-16T17:15:56.734112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'minkowski'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model.metric\n",
    "# dir(knn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:15:56.743816Z",
     "iopub.status.busy": "2021-10-16T17:15:56.743450Z",
     "iopub.status.idle": "2021-10-16T17:15:56.844151Z",
     "shell.execute_reply": "2021-10-16T17:15:56.843533Z",
     "shell.execute_reply.started": "2021-10-16T17:15:56.743777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([510.3334, 808.3334, 762.5   , 125.5   , 995.    ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model.predict(X_test)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:15:56.845525Z",
     "iopub.status.busy": "2021-10-16T17:15:56.845268Z",
     "iopub.status.idle": "2021-10-16T17:15:56.854803Z",
     "shell.execute_reply": "2021-10-16T17:15:56.854019Z",
     "shell.execute_reply.started": "2021-10-16T17:15:56.845488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404.7724696402799"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "y_pred = knn_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:15:56.856857Z",
     "iopub.status.busy": "2021-10-16T17:15:56.856384Z",
     "iopub.status.idle": "2021-10-16T17:15:56.914558Z",
     "shell.execute_reply": "2021-10-16T17:15:56.913940Z",
     "shell.execute_reply.started": "2021-10-16T17:15:56.856819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 RMSE: 419.07720589645663 \n",
      "\n",
      "k= 2 RMSE: 378.0502277324553 \n",
      "\n",
      "k= 3 RMSE: 392.2975443521745 \n",
      "\n",
      "k= 4 RMSE: 394.25060391156745 \n",
      "\n",
      "k= 5 RMSE: 404.7724696402799 \n",
      "\n",
      "k= 6 RMSE: 407.0381633460914 \n",
      "\n",
      "k= 7 RMSE: 400.1880716892174 \n",
      "\n",
      "k= 8 RMSE: 394.1365904297106 \n",
      "\n",
      "k= 9 RMSE: 398.66638869213017 \n",
      "\n",
      "k= 10 RMSE: 395.8693412183635 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Tuning\n",
    "RMSE = []\n",
    "\n",
    "for k in range(0,10):\n",
    "    k = k+1\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=k).fit(X_train, y_train)\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    RMSE.append(rmse)\n",
    "    print(\"k=\", k, \"RMSE:\", rmse, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:15:56.917566Z",
     "iopub.status.busy": "2021-10-16T17:15:56.917346Z",
     "iopub.status.idle": "2021-10-16T17:15:58.500149Z",
     "shell.execute_reply": "2021-10-16T17:15:58.499340Z",
     "shell.execute_reply.started": "2021-10-16T17:15:56.917520Z"
    }
   },
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "knn_params = {\"n_neighbors\": np.arange(1,30,1)}\n",
    "knn = KNeighborsRegressor()\n",
    "knn_cv_model = GridSearchCV(knn, knn_params, cv=10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:15:58.501828Z",
     "iopub.status.busy": "2021-10-16T17:15:58.501533Z",
     "iopub.status.idle": "2021-10-16T17:15:58.511112Z",
     "shell.execute_reply": "2021-10-16T17:15:58.510274Z",
     "shell.execute_reply.started": "2021-10-16T17:15:58.501779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 3}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:15:58.512888Z",
     "iopub.status.busy": "2021-10-16T17:15:58.512551Z",
     "iopub.status.idle": "2021-10-16T17:15:58.526449Z",
     "shell.execute_reply": "2021-10-16T17:15:58.525453Z",
     "shell.execute_reply.started": "2021-10-16T17:15:58.512848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392.2975443521745"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tuned Final Model\n",
    "knn_tuned = KNeighborsRegressor(n_neighbors= knn_cv_model.best_params_[\"n_neighbors\"]).fit(X_train, y_train)\n",
    "# Prediction\n",
    "y_pred = knn_tuned.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Support Vector Regression\n",
    "\n",
    "The objective of the support vector machine algorithm is to find a hyperplane in an N-dimensional space(N — the number of features) that distinctly classifies the data points.\n",
    "\n",
    "Hyperplanes are decision boundaries that help classify the data points. Data points falling on either side of the hyperplane can be attributed to different classes. Also, the dimension of the hyperplane depends upon the number of features. If the number of input features is 2, then the hyperplane is just a line. If the number of input features is 3, then the hyperplane becomes a two-dimensional plane. It becomes difficult to imagine when the number of features exceeds 3.\n",
    "\n",
    "Support vectors are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane. Using these support vectors, we maximize the margin of the classifier. Deleting the support vectors will change the position of the hyperplane. These are the points that help us build our SVM.\n",
    "\n",
    "\n",
    "![image.png](https://miro.medium.com/max/600/0*0o8xIA4k3gXUDCFU.png)\n",
    "\n",
    "**Source:**\n",
    "\n",
    "[Towards Data Science](https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:15:58.528111Z",
     "iopub.status.busy": "2021-10-16T17:15:58.527845Z",
     "iopub.status.idle": "2021-10-16T17:17:12.613238Z",
     "shell.execute_reply": "2021-10-16T17:17:12.612406Z",
     "shell.execute_reply.started": "2021-10-16T17:15:58.528075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(kernel='linear')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model and Prediction\n",
    "# We can change the svr kernel and we can try \"rbf\"\n",
    "svr_model = SVR(\"linear\").fit(X_train, y_train)\n",
    "svr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:17:12.615061Z",
     "iopub.status.busy": "2021-10-16T17:17:12.614785Z",
     "iopub.status.idle": "2021-10-16T17:17:12.624416Z",
     "shell.execute_reply": "2021-10-16T17:17:12.623497Z",
     "shell.execute_reply.started": "2021-10-16T17:17:12.615027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([300.20165327, 169.45346536, 519.37057457, 562.50758983,\n",
       "       686.05766456])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_model.predict(X_train)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:17:12.626651Z",
     "iopub.status.busy": "2021-10-16T17:17:12.626198Z",
     "iopub.status.idle": "2021-10-16T17:17:12.636761Z",
     "shell.execute_reply": "2021-10-16T17:17:12.635947Z",
     "shell.execute_reply.started": "2021-10-16T17:17:12.626518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([612.39761763, 556.79707247, 781.07233085, 306.47278181,\n",
       "       498.52104898])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_model.predict(X_test)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:17:12.638467Z",
     "iopub.status.busy": "2021-10-16T17:17:12.638218Z",
     "iopub.status.idle": "2021-10-16T17:17:12.645745Z",
     "shell.execute_reply": "2021-10-16T17:17:12.644881Z",
     "shell.execute_reply.started": "2021-10-16T17:17:12.638431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-43.67922349])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:17:12.647963Z",
     "iopub.status.busy": "2021-10-16T17:17:12.647587Z",
     "iopub.status.idle": "2021-10-16T17:17:12.656127Z",
     "shell.execute_reply": "2021-10-16T17:17:12.655247Z",
     "shell.execute_reply.started": "2021-10-16T17:17:12.647927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.52738022,   8.41603061,  -0.62248071,  -2.91633012,\n",
       "         -1.76348539,   4.05664922,   9.59333169,   0.01942209,\n",
       "         -0.6897988 ,   0.0252315 ,   1.61711037,   0.83482588,\n",
       "         -0.89443894,   0.25664992,   0.21656721,  -1.24359453,\n",
       "          2.77033446, -14.48688936,   0.46266861]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:17:12.658185Z",
     "iopub.status.busy": "2021-10-16T17:17:12.657840Z",
     "iopub.status.idle": "2021-10-16T17:17:12.669330Z",
     "shell.execute_reply": "2021-10-16T17:17:12.668572Z",
     "shell.execute_reply.started": "2021-10-16T17:17:12.658144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364.68986308043964"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "y_pred = svr_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:17:12.671348Z",
     "iopub.status.busy": "2021-10-16T17:17:12.670776Z",
     "iopub.status.idle": "2021-10-16T17:17:12.677476Z",
     "shell.execute_reply": "2021-10-16T17:17:12.676668Z",
     "shell.execute_reply.started": "2021-10-16T17:17:12.671310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(kernel='linear')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Tuning\n",
    "svr_model = SVR(\"linear\")\n",
    "svr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:17:12.679431Z",
     "iopub.status.busy": "2021-10-16T17:17:12.678945Z",
     "iopub.status.idle": "2021-10-16T17:21:13.896349Z",
     "shell.execute_reply": "2021-10-16T17:21:13.895417Z",
     "shell.execute_reply.started": "2021-10-16T17:17:12.679394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining penalty coef\n",
    "svr_params = {\"C\": [0.1, 0.5, 1, 3]}\n",
    "svr_cv_model = GridSearchCV(svr_model, svr_params , cv=5, verbose= 2, n_jobs= -1).fit(X_train, y_train)\n",
    "svr_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:21:13.898514Z",
     "iopub.status.busy": "2021-10-16T17:21:13.898239Z",
     "iopub.status.idle": "2021-10-16T17:21:15.106396Z",
     "shell.execute_reply": "2021-10-16T17:21:15.105573Z",
     "shell.execute_reply.started": "2021-10-16T17:21:13.898478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373.0293805913751"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_tuned = SVR(\"linear\", C = 0.1).fit(X_train, y_train)\n",
    "y_pred = svr_tuned.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) CART (Classification andd Regresson Tree)\n",
    "\n",
    "A decision tree is a largely used non-parametric effective machine learning modeling technique for regression and classification problems. To find solutions a decision tree makes a sequential, hierarchical decision about the outcomes variable based on the predictor data.\n",
    "The decision tree builds regression or classification models in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a decision tree with nodes and leaf nodes.\n",
    "The Understanding Level of Decision Tree algorithm is so easy as compared to the classification algorithm.\n",
    "In the Decision tree algorithm, we solve our problem in a tree regression.\n",
    "\n",
    "- **Each internal node of the tree corresponds to an attribute.**\n",
    "- **Each leaf node corresponds to a Class Label.**\n",
    "\n",
    "In the decision tree for predicting a class label for a record, we start from the root of the tree. We compare the value of the root attribute with the record’s attribute on the basis of comparison. We follow the branch corresponding to that value & jump to the next node. We continue comparing our record’s attribute value with other internal nodes of the tree until we reach a leaf node.\n",
    "\n",
    "![Decision Tree](https://ec.europa.eu/eurostat/statistics-explained/images/f/fb/Decision_tree.PNG)\n",
    "\n",
    "**Source:**\n",
    "\n",
    "[Medium](https://medium.com/machine-learning-researcher/decision-tree-algorithm-in-machine-learning-248fb7de819e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:21:15.108102Z",
     "iopub.status.busy": "2021-10-16T17:21:15.107863Z",
     "iopub.status.idle": "2021-10-16T17:21:15.133062Z",
     "shell.execute_reply": "2021-10-16T17:21:15.132434Z",
     "shell.execute_reply.started": "2021-10-16T17:21:15.108068Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/hitters-baseball-data/Hitters.csv\")\n",
    "df = df.dropna()\n",
    "# Transforming categorical data to dummy data\n",
    "dms = pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])\n",
    "y = df[\"Salary\"]\n",
    "X_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis= 1).astype(\"float64\")\n",
    "X = pd.concat([X_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "y,\n",
    "test_size = 0.2,\n",
    "random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:21:15.134612Z",
     "iopub.status.busy": "2021-10-16T17:21:15.134232Z",
     "iopub.status.idle": "2021-10-16T17:21:15.141085Z",
     "shell.execute_reply": "2021-10-16T17:21:15.139057Z",
     "shell.execute_reply.started": "2021-10-16T17:21:15.134571Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model & Prediction\n",
    "X_train = pd.DataFrame(X_train[\"Hits\"])\n",
    "X_test = pd.DataFrame(X_test[\"Hits\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:21:15.142729Z",
     "iopub.status.busy": "2021-10-16T17:21:15.142473Z",
     "iopub.status.idle": "2021-10-16T17:21:15.154390Z",
     "shell.execute_reply": "2021-10-16T17:21:15.153633Z",
     "shell.execute_reply.started": "2021-10-16T17:21:15.142695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_leaf_nodes=3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cart_model = DecisionTreeRegressor(max_leaf_nodes=3)\n",
    "cart_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:21:15.156076Z",
     "iopub.status.busy": "2021-10-16T17:21:15.155805Z",
     "iopub.status.idle": "2021-10-16T17:21:15.414315Z",
     "shell.execute_reply": "2021-10-16T17:21:15.413501Z",
     "shell.execute_reply.started": "2021-10-16T17:21:15.156042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Salary')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_grid = np.arange(min(np.array(X_train)), max(np.array(X_train)), 0.01)\n",
    "X_grid = X_grid.reshape((len(X_grid), 1))\n",
    "\n",
    "plt.scatter(X_train, y_train, color=\"red\")\n",
    "plt.plot(X_grid, cart_model.predict(X_grid), color = \"blue\")\n",
    "\n",
    "plt.title(\"CART Regression Tree\")\n",
    "plt.xlabel(\"Number of Hits\")\n",
    "plt.ylabel(\"Salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:21:15.415682Z",
     "iopub.status.busy": "2021-10-16T17:21:15.415409Z",
     "iopub.status.idle": "2021-10-16T17:21:15.424700Z",
     "shell.execute_reply": "2021-10-16T17:21:15.423752Z",
     "shell.execute_reply.started": "2021-10-16T17:21:15.415645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431.29048460063217"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One independet value prediction with Hits variable\n",
    "y_pred = cart_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:21:15.427160Z",
     "iopub.status.busy": "2021-10-16T17:21:15.426503Z",
     "iopub.status.idle": "2021-10-16T17:21:15.455246Z",
     "shell.execute_reply": "2021-10-16T17:21:15.454406Z",
     "shell.execute_reply.started": "2021-10-16T17:21:15.427081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412.18941897659465"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Many Independent value\n",
    "df = pd.read_csv(\"../input/hitters-baseball-data/Hitters.csv\")\n",
    "df = df.dropna()\n",
    "# Transforming categorical data to dummy data\n",
    "dms = pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])\n",
    "y = df[\"Salary\"]\n",
    "X_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis= 1).astype(\"float64\")\n",
    "X = pd.concat([X_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "y,\n",
    "test_size = 0.2,\n",
    "random_state =42)\n",
    "\n",
    "cart_model_2 = DecisionTreeRegressor(max_leaf_nodes=3).fit(X_train, y_train)\n",
    "y_pred = cart_model_2.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:21:15.460075Z",
     "iopub.status.busy": "2021-10-16T17:21:15.459858Z",
     "iopub.status.idle": "2021-10-16T17:21:15.463333Z",
     "shell.execute_reply": "2021-10-16T17:21:15.462361Z",
     "shell.execute_reply.started": "2021-10-16T17:21:15.460050Z"
    }
   },
   "outputs": [],
   "source": [
    "# ?cart_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:21:15.465645Z",
     "iopub.status.busy": "2021-10-16T17:21:15.464648Z",
     "iopub.status.idle": "2021-10-16T17:21:17.306475Z",
     "shell.execute_reply": "2021-10-16T17:21:17.305178Z",
     "shell.execute_reply.started": "2021-10-16T17:21:15.465585Z"
    }
   },
   "outputs": [],
   "source": [
    "cart_params = {\"max_depth\": [2,3,4,5,10,20],\n",
    "                   \"min_samples_split\": [2,10,5,30,50,10]}\n",
    "\n",
    "cart_model = DecisionTreeRegressor()\n",
    "cart_cv_model = GridSearchCV(cart_model, cart_params, cv=10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:21:17.309067Z",
     "iopub.status.busy": "2021-10-16T17:21:17.308428Z",
     "iopub.status.idle": "2021-10-16T17:21:17.317286Z",
     "shell.execute_reply": "2021-10-16T17:21:17.316629Z",
     "shell.execute_reply.started": "2021-10-16T17:21:17.309027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'min_samples_split': 50}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cart_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:21:17.318627Z",
     "iopub.status.busy": "2021-10-16T17:21:17.318266Z",
     "iopub.status.idle": "2021-10-16T17:21:17.345230Z",
     "shell.execute_reply": "2021-10-16T17:21:17.343901Z",
     "shell.execute_reply.started": "2021-10-16T17:21:17.318578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386.1879001714701"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final Model\n",
    "cart_model_tuned = DecisionTreeRegressor(max_depth=5, min_samples_split=50).fit(X_train, y_train)\n",
    "y_pred = cart_cv_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Random Forest Algorithm\n",
    "\n",
    "Random forest, like its name implies, consists of a large number of individual decision trees that operate as an ensemble. __Each individual tree__ in the random forest spits out a class prediction and the class with the most votes becomes our model’s prediction (see figure below).\n",
    "\n",
    "![Random Forest](https://static.javatpoint.com/tutorial/machine-learning/images/random-forest-algorithm2.png)\n",
    "\n",
    "The fundamental concept behind random forest is a simple but powerful one — the wisdom of crowds. In data science speak, the reason that the random forest model works so well is:\n",
    "\n",
    "- A large number of relatively uncorrelated models (trees) operating as a committee will outperform any of the individual constituent models.\n",
    "\n",
    "The low correlation between models is the key. Just like how investments with low correlations (like stocks and bonds) come together to form a portfolio that is greater than the sum of its parts, uncorrelated models can produce ensemble predictions that are more accurate than any of the individual predictions. The reason for this wonderful effect is that the trees protect each other from their individual errors (as long as they don’t constantly all err in the same direction). While some trees may be wrong, many other trees will be right, so as a group the trees are able to move in the correct direction. So the prerequisites for random forest to perform well are:\n",
    "\n",
    "- There needs to be some actual signal in our features so that models built using those features do better than random guessing.\n",
    "\n",
    "- The predictions (and therefore the errors) made by the individual trees need to have low correlations with each other.\n",
    "\n",
    "__What is Out-of-Bag Error ?__\n",
    "\n",
    "Out-of-bag (OOB) error, also called out-of-bag estimate, is a method of measuring the prediction error of random forests, boosted decision trees, and other machine learning models utilizing bootstrap aggregating (bagging). \n",
    "__Bagging uses subsampling with replacement to create training samples for the model to learn from__. OOB error is the mean prediction error on each training sample xi, using only the trees that did not have xi in their bootstrap sample.\n",
    "\n",
    "\n",
    "![OOB](https://upload.wikimedia.org/wikipedia/commons/7/77/OOB_Error_Example.png)\n",
    "\n",
    "Bootstrap aggregating allows one to define an out-of-bag estimate of the prediction performance improvement by evaluating predictions on those observations that were not used in the building of the next base learner.\n",
    "\n",
    "**Source:**\n",
    "\n",
    "[Towards Data Science](https://towardsdatascience.com/understanding-random-forest-58381e0602d2)\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Out-of-bag_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:21:17.347087Z",
     "iopub.status.busy": "2021-10-16T17:21:17.346454Z",
     "iopub.status.idle": "2021-10-16T17:21:17.369460Z",
     "shell.execute_reply": "2021-10-16T17:21:17.368826Z",
     "shell.execute_reply.started": "2021-10-16T17:21:17.347033Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model & Prediction\n",
    "\n",
    "df = pd.read_csv(\"../input/hitters-baseball-data/Hitters.csv\")\n",
    "df = df.dropna()\n",
    "# Transforming categorical data to dummy data\n",
    "dms = pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])\n",
    "y = df[\"Salary\"]\n",
    "X_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis= 1).astype(\"float64\")\n",
    "X = pd.concat([X_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "y,\n",
    "test_size = 0.2,\n",
    "random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:21:17.370973Z",
     "iopub.status.busy": "2021-10-16T17:21:17.370731Z",
     "iopub.status.idle": "2021-10-16T17:21:17.641614Z",
     "shell.execute_reply": "2021-10-16T17:21:17.640831Z",
     "shell.execute_reply.started": "2021-10-16T17:21:17.370941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305.03231392023173"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ?rf_model\n",
    "rf_model = RandomForestRegressor(random_state=42).fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-10-16T17:21:17.643392Z",
     "iopub.status.busy": "2021-10-16T17:21:17.643127Z",
     "iopub.status.idle": "2021-10-16T17:22:14.772460Z",
     "shell.execute_reply": "2021-10-16T17:22:14.771771Z",
     "shell.execute_reply.started": "2021-10-16T17:21:17.643357Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   15.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=   1.3s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=   1.4s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[CV] ............................................ C=0.5, total=   8.5s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[CV] ............................................ C=0.5, total=   7.4s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=  14.2s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=  23.3s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=  14.3s\n",
      "[CV] C=3 .............................................................\n",
      "[CV] .............................................. C=3, total= 1.1min\n",
      "[CV] C=3 .............................................................\n",
      "[CV] .............................................. C=3, total= 1.4min\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=2, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=2, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=2, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=2, n_estimators=500, total=   1.2s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=2, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=10, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=10, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=10, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=10, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=10, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=10, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=10, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=10, n_estimators=500, total=   1.2s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=10, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=10, n_estimators=500, total=   1.2s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=10, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=10, n_estimators=500, total=   1.2s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=100, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=100, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=100, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=100, n_estimators=500, total=   1.5s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=100, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=100, n_estimators=500, total=   1.2s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=100, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=100, n_estimators=500, total=   1.1s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=2, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=2, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=2, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=2, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=2, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=2, n_estimators=500, total=   1.4s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=10, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=10, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=10, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=10, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=10, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=10, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=10, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=10, n_estimators=200, total=   0.8s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=10, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=10, n_estimators=500, total=   1.9s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=10, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=10, n_estimators=500, total=   1.4s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=100, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=100, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=100, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=100, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=100, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=100, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=100, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=100, n_estimators=500, total=   1.2s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=100, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=100, n_estimators=500, total=   1.1s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=100, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=100, n_estimators=500, total=   1.1s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=2, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=2, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=2, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=2, n_estimators=500, total=   1.4s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=10, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=10, n_estimators=200, total=   0.6s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=10, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=10, n_estimators=200, total=   0.7s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=10, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=10, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=10, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=10, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=10, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=10, n_estimators=500, total=   1.2s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=10, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=10, n_estimators=500, total=   1.2s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=100, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=100, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=100, n_estimators=200 [CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=   1.4s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=   1.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=   0.7s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[CV] ............................................ C=0.5, total=   8.3s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[CV] ............................................ C=0.5, total=   6.7s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[CV] ............................................ C=0.5, total=   6.0s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=  16.3s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=  20.2s\n",
      "[CV] C=3 .............................................................\n",
      "[CV] .............................................. C=3, total=  46.2s\n",
      "[CV] C=3 .............................................................\n",
      "[CV] .............................................. C=3, total= 1.4min\n",
      "[CV] C=3 .............................................................\n",
      "[CV] .............................................. C=3, total=  47.4s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=2, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=2, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=2, n_estimators=500, total=   1.2s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=2, n_estimators=500, total=   1.2s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=2, n_estimators=500, total=   1.2s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=10, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=10, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=10, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=10, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=10, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=10, n_estimators=500, total=   1.2s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=10, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=10, n_estimators=500, total=   1.2s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=100, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=100, n_estimators=200, total=   0.4s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=100, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=100, n_estimators=200, total=   0.4s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=100, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=100, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=100, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=100, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=100, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=100, n_estimators=500, total=   1.4s\n",
      "[CV] max_depth=5, max_features=5, min_samples_split=100, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=5, min_samples_split=100, n_estimators=500, total=   1.1s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=2, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=2, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=2, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=2, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=2, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=2, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=2, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=2, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=2, n_estimators=500, total=   1.4s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=10, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=10, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=10, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=10, n_estimators=500, total=   2.0s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=10, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=10, n_estimators=500, total=   1.7s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=10, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=10, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=100, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=100, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=100, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=100, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=100, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=100, n_estimators=500, total=   1.2s\n",
      "[CV] max_depth=5, max_features=10, min_samples_split=100, n_estimators=500 \n",
      "[CV]  max_depth=5, max_features=10, min_samples_split=100, n_estimators=500, total=   1.2s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=2, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=2, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=2, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=2, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=2, n_estimators=500, total=   1.4s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=2, n_estimators=500, total=   1.7s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=10, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=10, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=10, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=10, n_estimators=500, total=   1.2s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=10, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=10, n_estimators=500, total=   1.2s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=10, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=10, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=100, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=100, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=100, n_estimators=200 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   56.8s finished\n"
     ]
    }
   ],
   "source": [
    "# Model Tuning\n",
    "\n",
    "rf_params = {\"max_depth\": [5,10], \n",
    "                 \"max_features\": [5,10], \n",
    "                 \"n_estimators\": [200,500], \n",
    "                 \"min_samples_split\": [2,10,100]}\n",
    "rf_cv_model = GridSearchCV(rf_model, rf_params, cv =5, verbose=2, n_jobs=-1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:22:14.773982Z",
     "iopub.status.busy": "2021-10-16T17:22:14.773711Z",
     "iopub.status.idle": "2021-10-16T17:22:14.779342Z",
     "shell.execute_reply": "2021-10-16T17:22:14.778709Z",
     "shell.execute_reply.started": "2021-10-16T17:22:14.773947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'max_features': 5,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:22:14.781227Z",
     "iopub.status.busy": "2021-10-16T17:22:14.780729Z",
     "iopub.status.idle": "2021-10-16T17:22:15.111343Z",
     "shell.execute_reply": "2021-10-16T17:22:15.110484Z",
     "shell.execute_reply.started": "2021-10-16T17:22:14.781192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323.2211498680023"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final Model\n",
    "rf_model = RandomForestRegressor(random_state=42, max_depth=8, max_features=2, min_samples_split=2, n_estimators=200)\n",
    "rf_tuned = rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_tuned.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "Feature importance refers to techniques that assign a score to input features based on __how useful they are at predicting a target variable.__\n",
    "\n",
    "There are many types and sources of feature importance scores, although popular examples include statistical correlation scores, coefficients calculated as part of linear models, decision trees, and permutation importance scores.\n",
    "\n",
    "![Feature Importance](https://scikit-learn.org/0.24/_images/sphx_glr_plot_permutation_importance_001.png)\n",
    "\n",
    "Feature importance scores play an important role in a predictive modeling project, including providing insight into the data, insight into the model, and the basis for dimensionality reduction and feature selection that can improve the efficiency and effectiveness of a predictive model on the problem.\n",
    "\n",
    "Source:\n",
    "\n",
    "[Machine Learning Mastery](https://machinelearningmastery.com/calculate-feature-importance-with-python/#:~:text=Feature%20importance%20refers%20to%20techniques,at%20predicting%20a%20target%20variable.&text=The%20role%20of%20feature%20importance%20in%20a%20predictive%20modeling%20problem.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:22:15.113138Z",
     "iopub.status.busy": "2021-10-16T17:22:15.112845Z",
     "iopub.status.idle": "2021-10-16T17:22:15.450499Z",
     "shell.execute_reply": "2021-10-16T17:22:15.449846Z",
     "shell.execute_reply.started": "2021-10-16T17:22:15.113100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets Check Hitters Dataset Feature Importance\n",
    "importance = pd.DataFrame({\"Importance\": rf_tuned.feature_importances_*100},\n",
    "                            index = X_train.columns)\n",
    "\n",
    "importance.sort_values(by = \"Importance\", axis= 0, ascending=True).plot(kind=\"barh\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.gca().legend = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Machines\n",
    "\n",
    "__What is Gradient Boosting?__\n",
    "\n",
    "Let’s start by understanding Boosting! __Boosting is a method of converting weak learners into strong learners.__ In boosting, each new tree is a fit on a modified version of the original data set. __The gradient boosting algorithm (gbm) can be most easily explained by first introducing the AdaBoost Algorithm.__\n",
    "\n",
    "The AdaBoost Algorithm begins by training a decision tree in which each observation is assigned an equal weight. After evaluating the first tree, we increase the weights of those observations that are difficult to classify and lower the weights for those that are easy to classify. \n",
    "\n",
    "The second tree is therefore grown on this weighted data. Here, the idea is to improve upon the predictions of the first tree. Our new model is therefore Tree 1 + Tree 2. We then compute the classification error from this new 2-tree ensemble model and grow a third tree to predict the revised residuals. We repeat this process for a specified number of iterations. Subsequent trees help us to classify observations that are not well classified by the previous trees. Predictions of the final ensemble model is therefore the weighted sum of the predictions made by the previous tree models.\n",
    "\n",
    "![GBM](http://explained.ai/gradient-boosting/images/golf-MSE.png)\n",
    "\n",
    "Gradient Boosting trains many models in a gradual, additive and sequential manner. __The major difference between AdaBoost and Gradient Boosting Algorithm is how the two algorithms identify the shortcomings of weak learners (eg. decision trees).__\n",
    "\n",
    "__While the AdaBoost model identifies the shortcomings by using high weight data points, gradient boosting performs the same by using gradients in the loss function__ (y=ax+b+e , e needs a special mention as it is the error term). \n",
    "\n",
    "The loss function is a measure indicating how good are model’s coefficients are at fitting the underlying data. A logical understanding of loss function would depend on what we are trying to optimise. For example, if we are trying to predict the sales prices by using a regression, then the loss function would be based off the error between true and predicted house prices. Similarly, if our goal is to classify credit defaults, then the loss function would be a measure of how good our predictive model is at classifying bad loans. One of the biggest motivations of using gradient boosting is that it allows one to optimise a user specified cost function, instead of a loss function that usually offers less control and does not essentially correspond with real world applications.\n",
    "\n",
    "![Gradient boosting](https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-030-34482-5_25/MediaObjects/482246_1_En_25_Fig2_HTML.png)\n",
    "\n",
    "\n",
    "**Source:**\n",
    "\n",
    "[Towards Data Science](https://towardsdatascience.com/understanding-gradient-boosting-machines-9be756fe76ab)\n",
    "\n",
    "[Akira AI](https://www.akira.ai/glossary/gradient-boosting/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:22:15.452103Z",
     "iopub.status.busy": "2021-10-16T17:22:15.451861Z",
     "iopub.status.idle": "2021-10-16T17:22:15.474797Z",
     "shell.execute_reply": "2021-10-16T17:22:15.474162Z",
     "shell.execute_reply.started": "2021-10-16T17:22:15.452070Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model & Prediction\n",
    "\n",
    "df = pd.read_csv(\"../input/hitters-baseball-data/Hitters.csv\")\n",
    "df = df.dropna()\n",
    "# Transforming categorical data to dummy data\n",
    "dms = pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])\n",
    "y = df[\"Salary\"]\n",
    "X_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis= 1).astype(\"float64\")\n",
    "X = pd.concat([X_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "y,\n",
    "test_size = 0.2,\n",
    "random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:22:15.476169Z",
     "iopub.status.busy": "2021-10-16T17:22:15.475935Z",
     "iopub.status.idle": "2021-10-16T17:22:15.580438Z",
     "shell.execute_reply": "2021-10-16T17:22:15.579665Z",
     "shell.execute_reply.started": "2021-10-16T17:22:15.476141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289.6528463648549"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model = GradientBoostingRegressor().fit(X_train, y_train)\n",
    "# ?gbm_model for learning the parameters\n",
    "y_pred = gbm_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-10-16T17:22:15.582109Z",
     "iopub.status.busy": "2021-10-16T17:22:15.581837Z",
     "iopub.status.idle": "2021-10-16T17:27:46.640041Z",
     "shell.execute_reply": "2021-10-16T17:27:46.639323Z",
     "shell.execute_reply.started": "2021-10-16T17:22:15.582075Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=100, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=100, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=100, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=100, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=100, n_estimators=500, total=   1.1s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=100, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=100, n_estimators=500, total=   1.1s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=100, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=100, n_estimators=500, total=   1.1s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=2, n_estimators=200, total=   0.6s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=2, n_estimators=200, total=   0.6s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=2, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=2, n_estimators=500, total=   2.0s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=2, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=2, n_estimators=500, total=   1.6s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=10, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=10, n_estimators=200, total=   0.6s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=10, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=10, n_estimators=200, total=   0.7s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=10, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=10, n_estimators=200, total=   0.6s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=10, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=10, n_estimators=200, total=   0.6s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=10, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=10, n_estimators=500, total=   1.4s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=10, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=10, n_estimators=500, total=   1.4s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=100, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=100, n_estimators=200, total=   0.9s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=100, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=100, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=100, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=100, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=100, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=100, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=100, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=100, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=100, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=100, n_estimators=500, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=1, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=1, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=1, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=0.8, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=0.8, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=0.8, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=0.5, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=0.8, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=0.8, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=100, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=100, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=100, n_estimators=500, total=   1.1s\n",
      "[CV] max_depth=10, max_features=5, min_samples_split=100, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=5, min_samples_split=100, n_estimators=500, total=   1.1s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=2, n_estimators=200, total=   0.6s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=2, n_estimators=200, total=   0.6s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=2, n_estimators=200, total=   0.6s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=2, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=2, n_estimators=500, total=   1.9s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=2, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=2, n_estimators=500, total=   1.5s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=2, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=2, n_estimators=500, total=   1.6s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=10, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=10, n_estimators=200, total=   0.6s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=10, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=10, n_estimators=500, total=   1.4s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=10, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=10, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=10, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=10, n_estimators=500, total=   1.9s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=100, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=100, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=100, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=100, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=100, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=100, n_estimators=500, total=   1.4s\n",
      "[CV] max_depth=10, max_features=10, min_samples_split=100, n_estimators=500 \n",
      "[CV]  max_depth=10, max_features=10, min_samples_split=100, n_estimators=500, total=   1.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=1, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=1, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=0.8, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=100, subsample=0.8, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=1, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=200, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=0.5, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=0.8, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=0.8, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=3, n_estimators=500, subsample=0.8, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=1, total=   0.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    9.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=1, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=1, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=1, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=0.8, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=0.8, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=0.8, total=   0.7s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=0.5, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=1, total=   1.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=1, total=   1.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=0.5, total=   0.7s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=0.5, total=   0.7s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=0.5, total=   0.7s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=0.8, total=   1.6s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=0.8, total=   1.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=0.8, total=   1.0s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=1, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=1, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=1, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=200, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=1, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=1, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=1, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=0.8, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=5, n_estimators=500, subsample=0.8, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=200, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=1, total=   1.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=1, total=   1.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=1, total=   1.2s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=0.5, total=   0.7s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=0.5, total=   0.7s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=0.8, total=   1.7s\n",
      "[CV] learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=ls, max_depth=8, n_estimators=500, subsample=0.8, total=   1.0s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=1, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=1, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=100, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=1, total=   0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 202 tasks      | elapsed:   49.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=1, total=   1.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=1, total=   1.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.5, total=   1.1s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.5, total=   1.2s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.5, total=   1.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.8, total=   1.2s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.8, total=   1.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=1, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=1, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=0.5, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=0.8, total=   0.7s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=0.8, total=   1.2s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=0.8, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=1, total=   2.1s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=1, total=   2.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.5, total=   1.6s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.5, total=   1.8s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.5, total=   1.6s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.8, total=   2.0s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.8, total=   2.0s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.8, total=   2.1s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=1, total=   0.9s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=200, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=1, total=   1.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=1, total=   1.5s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=1, total=   1.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.5, total=   1.1s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.5, total=   1.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.8, total=   1.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.8, total=   1.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.8, total=   1.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=1, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=1, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=1, total=   0.9s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=0.8, total=   0.9s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=0.8, total=   1.1s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=1, total=   2.1s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=1, total=   2.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=1, total=   2.9s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.5, total=   1.6s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.5, total=   1.9s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.8, total=   1.9s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.8, total=   2.0s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=1, total=   1.1s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=1, total=   1.2s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.5, total=   0.7s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=1, total=   1.1s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=1, total=   1.5s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.5, total=   0.7s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.8, total=   0.9s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.8, total=   0.9s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=1, total=   2.5s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=1, total=   2.9s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=1, total=   3.3s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.5, total=   1.7s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.5, total=   1.7s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.8, total=   2.8s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.8, total=   2.6s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1, total=   1.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1, total=   1.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1, total=   1.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5, total=   1.1s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5, total=   1.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8, total=   1.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8, total=   1.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8, total=   1.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.5, total=   0.7s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.8, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.8, total=   0.9s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.8, total=   0.9s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=1, total=   2.8s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=1, total=   3.0s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.5, total=   2.0s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.5, total=   1.8s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.5, total=   1.7s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.8, total=   2.1s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.8, total=   2.9s\n",
      "[CV] learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.8, total=   2.7s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1, total=   1.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1, total=   1.1s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5, total=   1.0s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5, total=   1.1s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5, total=   1.3s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8, total=   1.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8, total=   1.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1, total=   0.7s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5, total=   0.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8, total=   0.9s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8, total=   0.9s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8, total=   0.7s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1, total=   2.1s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1, total=   1.7s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5, total=   1.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5, total=   2.0s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5, total=   1.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8, total=   2.1s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8, total=   1.9s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8, total=   1.9s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1, total=   1.0s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1, total=   1.0s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1, total=   1.0s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5, total=   1.0s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5, total=   0.7s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8, total=   1.0s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8, total=   0.9s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1, total=   2.6s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1, total=   2.8s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1, total=   3.0s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5, total=   1.6s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5, total=   1.6s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8, total=   2.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8, total=   2.9s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=1, total=   0.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=1, total=   0.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=1, total=   0.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=1, total=   0.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=1, total=   0.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.8, total=   0.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.8, total=   0.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.8, total=   0.1s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8, total=   1.0s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8, total=   0.9s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1, total=   2.0s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1, total=   2.1s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1, total=   2.3s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5, total=   1.9s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5, total=   1.5s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8, total=   2.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8, total=   1.7s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1, total=   1.0s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1, total=   0.9s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5, total=   0.9s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5, total=   0.8s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8, total=   1.0s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8, total=   0.9s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8, total=   0.9s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1, total=   3.0s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1, total=   2.4s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5, total=   1.7s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5, total=   1.9s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5, total=   1.6s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8, total=   2.2s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8, total=   2.9s\n",
      "[CV] learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8, total=   2.4s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=1, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=0.8, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=1, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=1, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=1, total=   0.8s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=1, total=   0.9s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=1, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=0.5, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=0.8, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=0.8, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=200, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=0.8, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=3, n_estimators=500, subsample=0.8, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=1, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=200, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=1, total=   0.8s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=1, total=   0.9s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=0.5, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=0.8, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=0.8, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=5, n_estimators=500, subsample=0.8, total=   0.8s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=0.5, total=   0.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=1, total=   1.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=1, total=   1.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=1, total=   1.6s\n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=200, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=1, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=1, total=   1.3s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=0.5, total=   1.0s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=0.5, total=   0.8s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=0.5, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=0.8, total=   1.0s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=0.8, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=0.8, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=1, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=1, total=   0.9s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=0.8, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=0.8, total=   0.8s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=1, total=   1.2s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=1, total=   1.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=1, total=   1.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=0.5, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=0.5, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=0.8, total=   1.2s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=0.8, total=   1.2s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=0.8, total=   1.2s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=0.5, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=1, total=   0.9s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=1, total=   0.9s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=0.5, total=   0.8s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=0.5, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=0.8, total=   1.0s\n",
      "[CV] learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=ls, max_depth=8, n_estimators=500, subsample=0.8, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=1, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=1, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=1, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=1, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=100, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=1, total=   1.0s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=1, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=0.8, total=   0.8s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=200, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=1, total=   1.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=1, total=   1.2s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=0.5, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=0.5, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=0.5, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=0.8, total=   1.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=3, n_estimators=500, subsample=0.8, total=   1.2s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=1, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=100, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=1, total=   0.9s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=1, total=   0.9s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=0.5, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=0.8, total=   0.8s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=0.8, total=   0.8s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=1, total=   2.2s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=1, total=   2.7s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=1, total=   2.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 688 tasks      | elapsed:  4.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=1, total=   1.0s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=0.5, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=0.8, total=   0.8s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=0.8, total=   0.8s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=200, subsample=0.8, total=   0.8s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=1, total=   2.4s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=1, total=   2.5s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=0.5, total=   1.6s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=0.5, total=   1.7s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=0.5, total=   2.0s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=0.8, total=   2.5s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=0.8, total=   2.6s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=1, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=1, total=   1.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=1, total=   1.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=0.5, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=0.5, total=   0.8s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=0.5, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=0.8, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=0.8, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=0.8, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=1, total=   3.4s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=1, total=   4.1s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=0.5, total=   2.2s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=0.5, total=   2.2s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=0.5, total=   2.7s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=0.8, total=   3.1s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=0.8, total=   3.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=0.8, total=   3.1s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=0.5, total=   1.6s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=0.5, total=   1.8s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=0.8, total=   2.5s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=0.8, total=   2.5s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=5, n_estimators=500, subsample=0.8, total=   2.2s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=100, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=1, total=   1.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=1, total=   1.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=1, total=   1.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=0.5, total=   1.0s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=0.5, total=   0.9s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=0.8, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=200, subsample=0.8, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=1, total=   3.3s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=1, total=   3.6s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=1, total=   4.0s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=0.5, total=   2.2s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=0.5, total=   2.7s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=0.8, total=   3.5s\n",
      "[CV] learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=lad, max_depth=8, n_estimators=500, subsample=0.8, total=   3.1s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=1, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=1, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=1, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1, total=   1.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5, total=   1.0s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5, total=   1.0s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=1, total=   1.0s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=1, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1, total=   2.7s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1, total=   1.7s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5, total=   1.6s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5, total=   1.7s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5, total=   1.5s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8, total=   1.8s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8, total=   1.7s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=1, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=1, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=1, total=   1.0s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1, total=   1.5s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5, total=   1.0s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5, total=   1.0s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5, total=   1.0s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=1, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=1, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=1, total=   1.0s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=1, total=   0.9s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=1, total=   0.8s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5, total=   0.6s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8, total=   0.8s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1, total=   2.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1, total=   2.0s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1, total=   2.0s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5, total=   1.8s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5, total=   1.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8, total=   1.6s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8, total=   1.8s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8, total=   1.7s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=1, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5, total=   0.3s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8, total=   0.5s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=1, total=   1.2s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=1, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=1, total=   1.1s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5, total=   0.7s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8, total=   1.0s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8, total=   0.9s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1, total=   2.7s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed:  5.5min finished\n"
     ]
    }
   ],
   "source": [
    "# Model Tuning\n",
    "gbm_params = {\"learning_rate\": [0.001, 0.01], \n",
    "              \"max_depth\": [3,5,8], \n",
    "              \"n_estimators\": [100,200,500], \n",
    "              \"subsample\": [1,0.5,0.8], \n",
    "              \"loss\": [\"ls\", \"lad\", \"quantile\"] }\n",
    "\n",
    "gbm_cv_model = GridSearchCV(gbm_model, gbm_params, \n",
    "                            cv=5, verbose=2, \n",
    "                            n_jobs=-1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:27:46.641575Z",
     "iopub.status.busy": "2021-10-16T17:27:46.641335Z",
     "iopub.status.idle": "2021-10-16T17:27:46.647705Z",
     "shell.execute_reply": "2021-10-16T17:27:46.646879Z",
     "shell.execute_reply.started": "2021-10-16T17:27:46.641542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01,\n",
       " 'loss': 'ls',\n",
       " 'max_depth': 3,\n",
       " 'n_estimators': 500,\n",
       " 'subsample': 0.5}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:27:46.649829Z",
     "iopub.status.busy": "2021-10-16T17:27:46.649440Z",
     "iopub.status.idle": "2021-10-16T17:27:47.256164Z",
     "shell.execute_reply": "2021-10-16T17:27:47.255191Z",
     "shell.execute_reply.started": "2021-10-16T17:27:46.649782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290.73644681919285"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_tuned_model = GradientBoostingRegressor(learning_rate=0.1, loss= \"lad\", max_depth=5, n_estimators=200, subsample=1).fit(X_train, y_train)\n",
    "y_pred = gbm_tuned_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:27:47.257980Z",
     "iopub.status.busy": "2021-10-16T17:27:47.257687Z",
     "iopub.status.idle": "2021-10-16T17:27:47.586260Z",
     "shell.execute_reply": "2021-10-16T17:27:47.585614Z",
     "shell.execute_reply.started": "2021-10-16T17:27:47.257942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAEGCAYAAAA0UdFjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAs/UlEQVR4nO3debzWZZ3/8debRUFBDSHXEGUaU0FRDpbruGuTNVqm0lQyk6JmlpWVMzVFjk1Z5l760zTcJdfUHJdUJgQNDjuCYOIxcV8RFFDg8/vjum65uT0rnHPu5byfj8d5cH/36z4P5cP1/V7f96WIwMzMrFJ1K3cDzMzMmuNCZWZmFc2FyszMKpoLlZmZVTQXKjMzq2g9yt2AWtS/f/8YNGhQuZthZlZVpk6d+lpEDChd70LVAQYNGkR9fX25m2FmVlUkPdvYet/6MzOzilbxPSpJq4DZpLbOA06IiHeb2f8M4IrCPpI2BS4B9gYETAROj4jFLVx3rfO0yRtT4Ua1+TAzs6r2pY4JkKiGHtWyiBgWEUOA94BTWtj/DGCjouWrgIUR8Q8RMRh4BvhdK65beh4zMyuDiu9RlZgA7CrpAODMiDgSQNKlQD2wCbA18Iik14CTgOHAcUXnOBv4m6TBwMdaeZ5DSAWvDgjg6oi4oGO/qpmZQXX0qACQ1AP4NOk2YKMi4mLgBeDAiDgQ2BmYERGrivZZBcwAdmnDeYYB20TEkIgYCvy+kfaNllQvqf7VJevwBc3MrFHVUKh6S5pB6un8ndSz6WwLgR0kXSLpCODt0h0i4oqIqIuIugF9O7+BZma1qhpu/S2LiGHFKyStZO0i26uJY+cCwyR1i4jV+dhupB7SXGDL1pwnIt6UtBtwOOkZ2bHAv7f5m5iZWZtVQ6FqzLPAzpI2BHoDBwOP5m1LgL7AaxHxN0nTgR+Rnk2RP0/L21a05jyS+gPvRcRtkuYD1zfbun7D4Ut+j8rMrD1UZaGKiOck/QGYQxrFN71o8xXAfZJeyM+XvgZcIunpvP2xvK7V5yGNAPx97o0B/EfHfDMzMyslT5zY/urq6sLJFGZmbSNpakTUla6vhsEUZmbWhblQmZlZRavJQiVpS0k3S3pa0lRJ90r6R0lzSvYbI+nM/PlsSYfkz2dIciqFmVkFqMrBFM2RJOAO4JqIOD6v2w3YornjIuLHRYtnkEb2tT3nD5z1Z2a1pYMy/Fqr5goVcCDwfkRcXlgRETMlDWruIEljgXtI0UmOTzIzqxC1WKiGAFOb2DY4p1wUbAmcV7xDRFws6Tuk+KTXJA0nxycBSNqs/ZtsZmZNqcVC1Zyni1MuJI1pxTEfxCcBfwIeaGwnSaOB0QAD+693O83MLKvFwRRPkBLT20VEvAnsBownxSc1OkWIs/7MzDpGLfaoHgb+R9LoiLgCQNKuwKZtOMe6xyeBI5TMzNpRzfWoIkVtHA0ckoenPwH8HHipDacpxCc9AmwDjM/Ptq7H8UlmZp3KEUodwBFKZmZt5wglMzOrSi5UZmZW0VyozMysolX9qD9JWwIXAiOAt4CXSRFIM4H5wAakaey/FhHvd0qjHKFkZrWgzNFJBVXdoyrK9RsfEYMjYjhpVN4WrHm5dyiwLWn6eDMzqzJVXahoItcPeK5oeRUwmTTMHEkN+d0oJNVJGp8/j5F0taTxkhZK+mZev7GkP0maKWmOpOM67duZmVnV3/prLtcPAEm9gE8C32rF+T5BKn59gfmSLgOOAF6IiM/k8zX64rAjlMzMOka196iaUwigfRl4MSJmteKYP0XEioh4DXiFdAtxNnCopHMl7RcRixs70BFKZmYdo9oLVXO5foVnVIOB4ZI+l9evZM337lVyzIqiz6uAHhGxANiDVLDOkfRjzMys01T7rb8Wc/3yVB1nkQZZ3AU0kIrb/wJfaOkCkrYG3oiI6yW9BZzYYquc9Wdm1m6qukfVhly/O4GNJO0H/BS4SFI9qdfUkqHA5Hwb8SfAOe3UfDMzawVn/XUAZ/2ZmbWds/7MzKwquVCZmVlFq/lCJWlLSTfnZ1hTJd0r6R8lLZM0Q9JcSddK6pn3P0DS4rxtlqQ/S/po3jZK0qXl/UZmZl1LtY/6a1ZRxNI1EXF8XrcbRRFLkroDD5Iilm7Ih06IiCPz/j8HTiMNpGgdZ/2Z2fqokIy9SlHrPao2RywVy4WuL/BmxzfVzMwaU+uFqi0RS/cVrd4vD0f/O3AIcHVLF5I0WlK9pPpXl6x7g83MbG21Xqia01zE0oSIGBYRHwN+D/yypZM5QsnMrGPUeqFal4ilUncB+3dA28zMrBVqejAF6xaxVGpf4Ok2XdURSmZm7aame1TrGLEE+RmVpJnAV4DvdlabzcxsbbXeoyIiXqDx2X2HFO0TwG5F2xqdcyoixgJj27F5ZmbWgpruUZmZWfVzoTIzs4rmQmVmZhWtqp5RSdoSuBAYAbxFegdqBSki6c68z3zguog4Jy/fBtwQEbc3cc7xwJkRUS9paUT0We+GOkLJzAoch7TeqqZHVZTbNz4iBkfEcNKQ8mnA3nmfzYF3gL2KDt0LmNTJzTUzs3ZSNYWKpnP7HiIXqvzn3cAAJdsDyyLiJUmX5YijJyT9tLkLSeov6TFJn5G0laS/5OHqc4qGsJuZWSeoplt/TeX2TQWGSNqAVKj+D9gB2AnYnTW9qR9GxBs5Lf0hSbuWxCYBIGkL0ou/P4qIByV9F7g/In6Wj92oscZJGg2MBhjYf32+ppmZFaumHlWjImIFKSppD+BTwF+Bx0hFa29gYt71WEnTgOnALsDOjZyuJ6mH9v2IeDCvmwL8m6QxwNCIaDRy1ll/ZmYdo5oKVXO5fRNJeXx9I+JN4HHWFKpJ+RbgmcDBEbEr8CegVyPnWUnqoR1eWBERf8nnfh4YK+mr7fN1zMysNarp1l9zuX2TgF8D4/O+s0i9qy2AOcBQ0iCLxfnW3qeL9i0WwL8Dt0j6QUScK2k7YFFEXClpQ1LP7dpmW+qsPzOzdlM1hSoiQtLRwIWSfgAsBxqAM4D5pOdSP8/7rpT0CvBcRKwGZkqaDjxJmjRx4oev8MF1VkkaCdwlaQmpwH1P0vvAUsA9KjOzTqQUc2ftqa6uLurr3aMyM2sLSVMjoq50fTU9ozIzsy7IhcrMzCpa1Tyjao6kC4BnI+LCvHw/6fnUiXn518DzEXF+I8eOBe6JiFslNQB1EfHaejXIEUpm1c2xRxWlVnpUE1kTo9QN6E96V6pgbxyjZGZWlWqlUE1iTb7fLqQh6UskfSQPKd8JOEzSlByDdEXODmyUpN6S/lfSSZI2lvQnSTPzscd1/NcxM7OCmihUeRbflZIGknpPj5ESKvYC6oDZwKURMSIihgC9gSObOF0fUl7gTRFxJXAE8EJE7JaPva+xgySNzlmC9a82ml1hZmbroiYKVTaJNWkUj/HhGKUDJf1V0mzgINa+NVjsj8DvI6LwUu9s4FBJ50raLyIWN3aQI5TMzDpGLRWqwnOqoaRbf4+TelSF51O/BY6JiKHAlTQeoVQ4zxGFW4MRsYCURjEbOEfSjzvyS5iZ2dpqYtRfNomU57cwIlYBb0jajNRzOinv85qkPsAxwK1NnOfH+ec3wNclbQ28ERHXS3oLOLHFljhCycys3dRSoZpNGu13Y8m6PhHxmqQrST2tl0iJ6M35FnC1pF+S0tR/JWk18D5waru33MzMmuQIpQ7gCCUzs7ZzhJKZmVUlFyozM6toLlRmZlbRamkwRYskLY2IPkXLo0jZft+QdArwbkRcm9c/kF8kbjtn/ZlVJmf4VaUuVaiaExGXFy2OIo0QXLdCZWZm7caFKpM0hjSDbwMpdukGSctILw3/BPgcsJLU0zqzTM00M+tyulqh6i1pRtFyP+Cu4h3ydB/fAM6MiHpJmwNHA5+IiMgvEX+IpNHAaICB/Tui6WZmXVNXG0yxLCKGFX5ICRQtWQwsB66S9Hng3cZ2ctafmVnH6GqFqs0iYiWwJyly6UiaSE83M7OO0dVu/bXWEqAvQM4G3Cgi7pU0EVjY4tHO+jMzazcuVI0bC1yeB1N8GvijpF6AgO+Us2FmZl2Ns/46gLP+zMzazll/ZmZWlVyozMysotXkMypJRwF3ADtFxJOShgFbR8S9efso4FfA80BPYB7w1YhodOh5PuYA4L2ImNRiAxyhZFZZHJ1U1Wq1RzUSeDT/CTAM+OeSfcbl96l2Ad4DjmvhnAeQprU3M7NOVHOFKg8n3xf4GnC8pA2As4HjJM2QdFzJ/j2AjYE38/JnJf1V0nRJf5a0haRBwCnAt/M59uvM72Rm1pXVXKEC/gW4LyIWAK8DQ0kJFIUe1Li833E5Tul5UpTS3Xn9o8CnImJ34Gbg+xHRAFwOXJDPMaH0opJGS6qXVP/qkg78dmZmXUwtFqqRpAJD/nNkE/uNyzFKWwKzge/l9dsC90sqrNulNRd1hJKZWceoqUIlqR9wEPA7SQ2kQnMs6UXdRkV6kexuYP+86hLg0ogYCpwM9OrINpuZWfNqbdTfMcB1EXFyYYWk/wMGkiORmrAv8HT+vCnpdiDACUX7LAE2aVUrHKFkZtZuaqpHRbrNd0fJuttIt/d2LhlMURhcMQvYHfjvvH4McIukqcBrRee5GzjagynMzDqXI5Q6gCOUzMzazhFKZmZWlVyozMysotVcoVLyqKRPF637oiRPeGhmVoVqbdQfERGSTiENiHiE9B3/BzhiXc4nqUee5bf1nPVnVlmc9VfVaq5HBRARc0ij9H5ASqW4HvihpMk5GulfACQNkjRB0rT8s3def0BefxcwV9LGkv4kaaakOaUxTGZm1nFqrkdV5KfANFLg7D3AwxHx75I2AyZL+jPwCnBoRCyX9HHgJqAw4mQPYEhEPCPpC8ALEfEZAEmbdvJ3MTPrsmq2UEXEO5LGAUtJ6RSflXRm3tyL9BLwC8CleRqQVcA/Fp1ickQ8kz/PBn4t6Vzgnqay/oDRAAP7d8AXMjPromq2UGWr84+AL0TE/OKNksYALwO7kW6DLi/a/E7hQ0QskLQHaaqQcyQ9FBFnF58rIq4ArgCo20G+IW5m1k5qvVAV3A+cLun0PNhi94iYTopLWhQRqyWdAHRv7GBJWwNvRMT1kt4CTmz2ao5QMjNrN12lUP03cCEwS1I34BngSOC3wG2SvgrcR1EvqsRQ4FeSVgPvA6d2eIvNzAxwhFKHcISSmVnbOULJzMyqkguVmZlVNBcqMzOraDUxmELSKtK7TgU3R8QvytUeRyiZdTJHJNW0mihUwLKIGNbcDpK6R8SqppZbe5yZmXWumr71J6lB0rmSpgFfbGR5pKTZOb/v3KLjlkr6taSZwF6SfiFprqRZks4r2xcyM+uCaqVH1VvSjKLln0fEuPz59YjYA0DSLwrL+SXex4HhwJvAA5KOiog7gY2Bv0bEdyVtDlwFfCK/LLxZYw1whJKZWceolULV3K2/cU0sjwDGR8SrAJJuAPYH7iTl/t2W91tMila6StI9pIDbD3GEkplZx6jpW39ZadpEU+kTxZYXnkvluaj2BG4lpVl4AkYzs05UKz2qdTEZuFhSf9Ktv5HAJaU7SeoDbBQR90qaCCxs8czO+jMzaze1UqhKn1HdFxFnNXdARLwo6SzgEVK6+p8i4o+N7NoX+KOkXnm/77RTm83MrBVqolBFRKOp5xExqIXlm0iTJZYe16fo84ukW39mZlYGXeEZlZmZVTEXKjMzq2g1ceuvKUXRSj1Ic1B9JSLeKmujzMysTWq6UFH0fpWka4DTgJ91+FWd9WfWds7rsyZ0pVt/jwHbAEgaL6kuf+4vqSF/HiXpdkn3SXpK0i/z+u6SxuaopdmSvl2uL2Fm1tXUeo8KSIUGOJgUhdSSYcDuwApgvqRLgI8C20TEkHy+zTqmpWZmVqrWe1SF96teArYAHmzFMQ9FxOKIWA7MBbYjveS7g6RLJB0BvF16kKTRkuol1b+6pP2+gJlZV1frharwjGo70su6p+X1K1nz3XuVHLOi6PMqoEdEvAnsBowHTgF+V3qhiLgiIuoiom5A33Zrv5lZl9clbv1FxLuSvgncKem3QAMpNX0ycExLx+eYpfci4jZJ84Hrmz3AEUpmZu2mSxQqgIiYLmkWKdPvPOAPeWqOP7Xi8G2A30sq9ML+o4OaaWZmJRThIaHtra6uLurr3aMyM2sLSVMjoq50fa0/ozIzsyrnQmVmZhXNhcrMzCpaVQ6mkHQUcAewU0Q82cZjzwb+EhF/bubcCyJi7jo30BFKZi1zZJK1UrX2qEYCj+Y/2yQiftxUkcqOAnZex3aZmVk7q7pClaeG3xf4GnB8XreVpL9ImpHz+PZrKp8vrzsmf/6FpLmSZkk6T9LewOeAX+VzDZb0zaJ9bi7T1zYz67Kq8dbfv5Cmml8g6XVJw4EDgPsj4mc5128jUmZfk/l8kjYHjgY+EREhabOIeEvSXcA9EXFr3u8sYPuIWNFcxl9+J2s0wMD+7fp9zcy6tKrrUZFu9xV6Njfn5SnAv0kaAwyNiCW0nM+3GFgOXCXp88C7TVxvFnCDpC+Topca5QglM7OOUVWFSlI/4CDgd3lqju8BxwITgP2B54Gxkr7aUj5fRKwE9gRuBY4E7mvisp8BfgPsAUyRVI29UDOzqlVtf+keA1wXEScXVkj6P1KRejQirpS0IbCHpHtpJp8vP+vaKCLulTSR1AMDWAL0zft0Az4WEY9IepT0TKwP8FazrXTWn5lZu6m2QjUSOLdk3W3AWOAdSe8DS4Gv0nI+X1/gj5J6kZLVv5PX3wxcmUNsjyfdGtw073Oxp7I3M+tczvrrAM76MzNrO2f9mZlZVXKhMjOzitZlC5WkVUUvCN9deEdK0iBJy/K2mZImSdoxbztA0j1lbbiZWRdTbYMp2lNhmnokXUOapv5nedvTRdtOBv4TOKHVZ3bWn1nznPNnbdBle1QlHiONEmzMJsCbndgWMzMr0pV7VADkyKWDgauKVg+WNIM0hH0j4JOtOI8jlMzMOkBX7lH1zsXoJWAL4MGibU9HxLCIGAycAVzR0skcoWRm1jG6cqEqPKPajvQy72lN7HcXKfnCzMzKoMvf+ouId3MKxZ2SftvILvsCT7fppI5QMjNrN12+UAFExHRJs0gRTRNY84xKwHvAiWVsnplZl9ZlC1VE9ClZ/mzRYu8mjhlPSmM3M7NO0pWfUZmZWRVwoTIzs4rmQmVmZhWtKp9RSdoSuBAYQZrE8GXgjIhYIOkM4BfAFhGxOO9/AGkSxUl5eQxwEvAq0At4BDgtIlY3c82jgAURMbfFBjpCyWxtjkyy9VB1PSpJAu4AxkfE4IgYTpoUcYu8y0hgCvD5osMOAPYuOdUF+T2qnYGhwD+1cOmj8r5mZtaJqq5QAQcC70fE5YUVETEzIiZIGkyaKv5HpIKFpEHAKcC3cyL6fiXn24DUq3oz73+SpCk5Of02SRtJ2hv4HPCrfI7BHf0lzcwsqcZCNQSY2sS240lTyU8AdpS0RUQ0AJeTe1ARMSHv++38rtSLpFt6M/L62yNiRETsBswDvpZvGd4FfC+f40MvAEsaLaleUv2rS9rni5qZWXUWquaMBG7Oz5puA77YzL6FW38fBTaWdHxeP0TSBEmzgX8FdmnNhZ31Z2bWMaqxUD0BDC9dKWko8HHgQUkNpN7VyJZOFhHvA/exJs9vLPCNiBgK/JR0W9DMzMqkGkf9PQz8j6TREXEFgKRdgYuAMRHx88KOkp6RtB2whDSv1IfkwRn7ANPzqr7Ai5J6knpUz+f1S/K2ljnrz8ys3VRdjyoiAjgaOETS05KeAH5OGtl3R8nud5B6VncDR5cMpig8o5oDdAcKgbT/BfwVmAg8WXSum4HvSZruwRRmZp1H6e99a091dXVRX+8elZlZW0iaGhF1peurrkdlZmZdiwuVmZlVtIobTNFUPBLp/aYhRfuNAZZGxHltOPcqYDbpez8DfCUi3mqflhdxhJJVE8cbWYWrqB5VK+KR1tey/MLuEOANmp5+3szMKkRFFSqaiEcCnmvuIEnjJV2QkyHmSRoh6XZJT0k6p4nDHgO2KTq+Ln/un9/DQtKofJ778rl+2Q7f0czM2qDSbv01F49UmB6+YEug+LbfexFRJ+lbwB9JLwW/ATwt6YKIeL2wo6TuwMHAVa1o0zBgd2AFMF/SJRHxocIpaTQwGmBg/1ac1czMWqXSelTNeTrfthuWo48uL9l+V/5zNvBERLwYESuAhcDH8rbeudi9RLqd+GArrvtQRCyOiOXAXGC7xnZyhJKZWceotELVaDxSK63If64u+lxYLvQcl+Uitx0g1jyjWsma30VpZFLxuVZReb1QM7OaVml/6TYVj7Rpe14kIt6V9E3gTkm/BRpIBXIycMx6X8ARSmZm7aaielTNxCO91AHXmg7MIgXXngecKmk64CdMZmYVxBFKHcARSmZmbecIJTMzq0ouVGZmVtFcqMzMrKJV2qi/ZklaGhF9ipZHAXUR8Y02nKOBNAliAG8CX42IZ9u1oc76s47iXD7rgrpqj+rAiNgVGA/8qMxtMTOzZtRMoZI0VtJlkh6XtFDSAZKuztl/Y5s4rDjvb6ykY4rOtzT/eUDOArxV0pOSbsjhuWZm1gmq6tYfayKQCvqxJjoJ4CPAXsDn8vp9gBOBKZKGRUTxsQBHAHe24rq7A7sAL5CmqN8HeLR4B2f9mZl1jGrrUS0ryfv7ccn2u/NLw7OBlyNidkSsJkUzDSra7xFJzwOfBm5qxXUnR8SifK4ZJecCnPVnZtZRqq1QtaQ1eX+QphPZjlR0fprXfZD3J6kbsEEj5wXn/ZmZdaou+xduRKyUdAYwO89Z1UDK+/sD6dZhz3U+ubP+zMzaTa31qNokIl4k3fo7DbgS+CdJM0nPud4pZ9vMzCxx1l8HcNafmVnbOevPzMyqkguVmZlVtC47mKJDdXaEkmN1zKyGdXiPStIqSTMkPSFppqTv5uHfSKqTdHELx58i6avNbP+cpLPasb13SDqqaHm+pB8VLd8m6fPtdT0zM2teZ/SoluWXc5H0UeBGYBPgJxFRDzQ76iAiLm9h+12snU6xviYCe5Omqd+cNPpvr6Lte5FGCZqZWSfo1GdUEfEKKWboG0oOkHSPpG6SGiRtVthX0lOStpA0RtKZed03Jc2VNEvSzXndKEmX5s+DJD2ctz8kaWBeP1bSxZIm5RzAYz7UuDUmkQoV+c+7gQG5vduTCu9LpQdJGi2pXlL9q0vW+1dlZmZZpw+miIiFQHfgo0XrVgN/BI4GkPRJ4NmIeLnk8LOA3XPy+SmNnP4S4Jq8/Qag+LbiVsC+wJHAL5pp4lRgiKQNSIXqMWA+sFNentTE93KEkplZB6ikUX/jgOPy5+PzcqlZwA2SvkyKPCq1F+nWIsB1pMJUcGdErI6IucAWTTUiIlaQsgH3AD4F/JVUrPbOPxNb+4XMzGz9dfqoP0k7kPLyXiH1UgoeA/5B0gDgKOCcRg7/DLA/8Fngh5KGtuHSxXl9LQ3Jm5iv0zci3pT0OPANUor6/2vxSo5QMjNrN53ao8pF6HLg0iiJxMjLdwDnA/Mi4vWSY7sBH4uIR4AfAJsCfVjbJFJvDOBfgQnr2NRJwMnAzLw8i9S7GgjMWcdzmpnZOuiMHlVhDqmepNt115GKUWPGAVOAUY1s6w5cL2lTUo/o4oh4q2QOw9OB30v6HvAq8G/r2OZJwA7Az+GDANtXgOfy8zQzM+skzvrrAM76M6su77//PosWLWL58uXlbkqX0KtXL7bddlt69lx7koqmsv6cTGFmXd6iRYvo27cvgwYNouQujbWziOD1119n0aJFbL/99q06pssWqjwQ47qS1Ssi4pPlaI+Zlc/y5ctdpDqJJDbffHNeffXVVh9TtkIlaWlElA6G6DQRMRsY1tw+ksYA3wcG5ZeVW9fuzsj6c76fWbtykeo8bf1dV9J7VJXqNeC75W6EmVlXVVG3/iQNBn4DDADeBU6KiCclfRb4EbAB8DrwrxHxch7ufiOwNek9rENJ08n3Ae6JiCH5vGcCfSJiTFPXaKZZVwOjJJ0bEW+0/7c2s4rT3ndEWnEHpE+fPixdurR9r9uMhoYGJk2axJe+9KVOu+a6qrQe1RXA6RExHDgT+G1e/yjwqYjYHbiZdDsO4CfAwxGxC3Ar6T2ndb1GU5aSitW3mtvJWX9mVi1WrlxJQ0MDN954Y8s7V4CK6VFJ6kOKKLql6P7lhvnPbYFxkrYi9aqeyev3JecDRsR9kt5cj2s052JghqTzmtohIq4gFUHqdpAfIJnZOhk/fjw/+clP2GyzzZg9ezbHHnssQ4cO5aKLLmLZsmXceeedDB48mFGjRtGrVy/q6+t5++23Of/88znyyCNZvnw5p556KvX19fTo0YPzzz+fAw88kLFjx3L77bezdOlSVq1axYoVK5g3bx7Dhg3jhBNO4Oijj+YrX/kK77zzDgCXXnope++9N+PHj2fMmDH079+fOXPmMHz4cK6//nokMWXKFL71rW/xzjvvsOGGG/LQQw+x0UYbcdZZZzF+/HhWrFjBaaedxsknn7xev5OKKVSk3t1bhSlBSlwCnB8Rd0k6ABjTwrlWsnZvsVcrrtGk/GLxjbR2eg9HKJnZepg5cybz5s2jX79+7LDDDpx44olMnjyZiy66iEsuuYQLL7wQSLfvJk+ezNNPP82BBx7I3/72N37zm98gidmzZ/Pkk09y2GGHsWDBAgCmTZvGrFmz6NevH+PHj+e8887jnnvuAeDdd9/lwQcfpFevXjz11FOMHDmSwvug06dP54knnmDrrbdmn332YeLEiey5554cd9xxjBs3jhEjRvD222/Tu3dvrrrqKjbddFOmTJnCihUr2GeffTjssMNaPRS9MRVz6y8i3gaekfRFgDytxm5586bA8/nzCUWHTQSOzfsfBnwkr38Z+KikzSVtSEpMb+kaLTmfFKtUScXdzGrQiBEj2Gqrrdhwww0ZPHgwhx12GABDhw6loaHhg/2OPfZYunXrxsc//nF22GEHnnzySR599FG+/OUvA/CJT3yC7bbb7oNCdeihh9KvX79Gr/n+++9z0kknMXToUL74xS8yd+7cD7btueeebLvttnTr1o1hw4bR0NDA/Pnz2WqrrRgxYgQAm2yyCT169OCBBx7g2muvZdiwYXzyk5/k9ddf56mnnlqv30c5/9LdSNKiouXzSfl8l+UZdXuSnkfNJPWgbsm39h4GCqX5p8BNkr5CGkzxErAkIt6XdDYwmVTgigdLNHWNZkXEa5LuAL69jt/XzKxVNtxwzROJbt26fbDcrVs3Vq5cM3FE6TDvloZ9b7zxxk1uu+CCC9hiiy2YOXMmq1evplevXh9sK25P9+7d12pDqYjgkksu4fDDD2+2LW1RtkIVEU315o5oZN8/kuarKrUYODxn8e0FjMjTdBARF7P2fFSFcz3T2DWaaOOYkuXvAN9pzbFmZh3tlltu4YQTTuCZZ55h4cKF7Ljjjuy3337ccMMNHHTQQSxYsIC///3v7LjjjkybNm2tY/v27cuSJWtGfi1evPiDXtM111zDqlWrmr32jjvuyIsvvsiUKVMYMWIES5YsoXfv3hx++OFcdtllHHTQQfTs2ZMFCxawzTbbNFskW1Ltt7EGAn/IyervASeVuT1mVguq5IX6gQMHsueee/L2229z+eWX06tXL77+9a9z6qmnMnToUHr06MHYsWPX6hEV7LrrrnTv3p3ddtuNUaNG8fWvf50vfOELXHvttRxxxBEtFpYNNtiAcePGcfrpp7Ns2TJ69+7Nn//8Z0488UQaGhrYY489iAgGDBjAnXfeuV7f06G0gKQfAl8sWX1LRPxsXc7nUFqz6jJv3jx22mmnlnesIKNGjeLII4/kmGOOKXdT1kljv3OH0jYjF6R1KkqN6sgIpSr5l56ZWXtpcdSfpJD066LlM3MG3jqTdICke9bnHJ1B0nhJ9UXLdZLGl7FJZmYAjB07tmp7U23VmuHpK4DPS+rf0Y2pUB+V9OlyN8LMOpYfg3Setv6uW1OoVpISFz40LFvSAEm3SZqSf/bJ62dL2iy/p/S6pK/m9ddKOrSpC0k6TNJjkqZJuiUnSSDpx/n8cyRdoTwGU9IISbMkzZD0K0lz8vpRki4tOu89+UXhJq/RjF8BP2zpl+QIJbPq1atXL15//XUXq05QmI+qePh7S1r7jOo3wCxJvyxZfxFwQUQ8KmkgcD+wE+lF3H2AZ4GFwH7AtcBewKnAiNIL5B7bj4BDIuIdST8gDQU/G7g0Is7O+11HeoH3buD3pFDZxyT9oqUv0cI1mvIYcLSkA4EmS5AjlMyq17bbbsuiRYvaNEeSrbvCDL+t1apCFRFvS7oW+CawrGjTIcDORS+ZbZJ7KBOA/UmF6jJgtKRtgDdzgWjsMp8CdgYm5u0bkIoEwIGSvg9sBPQDnpA0AegbEYV9biQnUDSjuWs05xxSgftBK/Y1syrTs2fP9Yr4sY7VllF/FwLTSL2Ygm6kVPPlxTtK+gspF28g6bbZ0cAxpALWFAEPRsTIknP1IiWc10XEc3kgR0t9xqay/hq9Rksi4mFJ55AKXcuc9Wdm1m5anfWX52L6A/C1otUPAKcXFiQNy/s+B/QHPh4RC0nTdJwJ/KWZSzwO7CPpH/K5Npb0j6wpMq/l3tox+RpvAUskFaaOP77oXA3AMEndJH0M2LOFa7TGOayZXsTMzDpJW0Npf00qQAXfBOrygIa5wClF2/4KLMifJwDbkApWwcGSFhV+gH8ARpGy+2aRbsl9IhekK4E5pGdgU4rO8TXgSkkzgI1JkUqQnpE9A8wlxShNA4iIVxu7Rmu+eETcC/gGtplZJ6vqZApJfSJiaf58FrBVRDQ7wWFnkLQEmF/udjSiP/BauRvRiEptF1Ru29yutqnUdkHltq0c7douIgaUrqz2ZIrPSPoP0vd4ltRbqgTzG4sBKTdJ9W5X21Rq29yutqnUdkHltq2S2lXVhSoixgHj1vc8efqO0iE/P4iI+9f33GZmtn6qulC1l4g4utxtMDOzxlXMDL815opyN6AJblfbVWrb3K62qdR2QeW2rWLaVdWDKczMrPa5R2VmZhXNhcrMzCqaC1U7knSEpPmS/pbf66oIkq6W9EohXb5SSPqYpEckzZX0hKSyvwMHKbZL0mRJM3O7flruNhWT1F3S9Eqb001SQ545YYaK5nErtzyTw62SnpQ0T9JeFdCmHfPvqfDztqQzyt0uAEnfzv/dz5F0U46xK2+b/IyqfUjqTkriOBRYRErQGBkRc8vaMEDS/sBS4NqIGFLu9hRI2or0kvY0SX2BqcBR5f6d5WlkNo6IpZJ6khJVvhURj5ezXQWSvgPUAZtEREtBzJ1GUgMpk7OiXl6VdA0wISJ+J2kDYKOceFMR8t8dzwOfjIhny9yWQoLQzhGxTNIfgHsjYmw52+UeVfvZE/hbRCyMiPeAm4F/KXObAIiIvwBvlLsdpSLixYgoxFstAeaRorbKKpKlebFn/qmIf9FJ2hb4DPC7crelGkjalDSTw1UAEfFeJRWp7GDg6XIXqSI9gN6SepBmrHihzO1xoWpH2wDPFS0vogL+0q0WkgYBu5MyIssu316bAbxCStyviHaRZjH4PrC6zO1oTAAPSJoqaXS5G5NtT8ro/H2+Xfo7SRuXu1EljgduKncjACLieeA84O/Ai8DiiHigvK1yobIKkFPxbwPOiIi3y90egIhYFRHDgG2BPSWV/ZappCOBVyJiarnb0oR9I2IP4NPAafmWc7n1APYALouI3YF3gEp6frwB8DnglnK3BUDSR0h3grYHtgY2lvTl8rbKhao9PQ98rGh527zOmpGfAd0G3BARt5e7PaXybaJHgCPK3BRIs2Z/Lj8Luhk4SNL15W3SGvlf40TEK8AdrJlep5wWAYuKesS3kgpXpfg0MC0iXi53Q7JDgGci4tWIeB+4Hdi7zG1yoWpHU4CPS9o+/yvpeOCuMrepouVBC1cB8yLi/HK3p0DSAEmb5c+9SQNknixro4CI+I+I2DYiBpH++3o4Isr+r134YG63voXPwGGkqXnKKiJeAp6TtGNedTBp+p9KMZIKue2X/R34lKSN8v+fB5OeHZeVs/7aSUSslPQN0pxZ3YGrI+KJMjcLAEk3AQcA/fPcXz+JiKvK2yog9RC+AszOz4MA/jPP/VVOWwHX5NFY3YA/RERFDQWvQFsAd6S/2+gB3BgR95W3SR84Hbgh/wNyIfBvZW4P8EFBPxQ4udxtKYiIv0q6lTSH30pgOhUQpeTh6WZmVtF868/MzCqaC5WZmVU0FyozM6toLlRmZlbRXKjMzKyiuVCZtYGkVSWp14PW4RxHSdq5A5qHpEGdnZIvaZikf+7Ma1rX4veozNpmWY5WWh9HAffQhhdPJfWIiJXred12l4NLh5HS3Mv9/pvVKPeozNaTpOGS/i+Hsd6fpy9B0kmSpuR5rW7Lb/vvTcp2+1XukQ2WNF5SXT6mf45IQtIoSXdJehh4KKc/XJ3nypouqdl0/nz8nZIezHNFfUPSd/Kxj0vql/cbL+mi3J45kvbM6/vl42fl/XfN68dIuk7SROA64GzguHz8cZL2lPRYvs6kQipEbs/tku6T9JSkXxa19QhJ0/Lv6qG8rk3f12pYRPjHP/5p5Q+wCpiRf+4gTQEyCRiQtx9HSiUB2LzouHOA0/PnscAxRdvGk+ZxAugPNOTPo0hZdf3y8v8AX86fNyPNf7ZxSfsGAXOKjv8b0BcYACwGTsnbLiCFABeuf2X+vH/R8ZeQUkwADgJm5M9jSHOH9S66zqVFbdgE6JE/HwLcVrTfQmBToBfwLCkfcwBp5oHt836t/r7+6Ro/vvVn1jZr3frLqepDgAdzfFB30vQIAEMknUP6S7YPKV6rrR6MiMJcYoeRQmnPzMu9gIE0n8X2SKS5vpZIWgzcndfPBnYt2u8mSHOXSdokZx3uC3whr39Y0uaSNsn73xURy5q45qakCKqPk6b+6Fm07aGIWAwgaS6wHfAR4C8R8Uy+1vp8X6tBLlRm60fAExHR2PTmY0kzFs+UNIqUt9iYlay5DV867fc7Jdf6QkTMb0P7VhR9Xl20vJq1//8vzVJrKVvtnWa2/TepQB6dB5uMb6I9q2j+76B1+b5Wg/yMymz9zAcGSNoL0rQlknbJ2/oCLypNZfKvRccsydsKGoDh+fMxzVzrfuD0nGqNpN3Xv/kfOC6fc1/SZHmLgQnkdks6AHgtGp8vrPT7bMqaKW5GteLajwP7S9o+X6tfXt+R39eqiAuV2XqIiPdIxeVcSTNJz64K8/f8F2nG4omsPU3IzcD38gCBwaQZVU+VNJ30jKop/026jTZL0hN5ub0sz9e/HPhaXjcGGC5pFvAL4IQmjn0E2LkwmAL4JfDzfL4W79pExKvAaOD2/Dsclzd15Pe1KuL0dLMuTtJ44MyIqC93W8wa4x6VmZlVNPeozMysorlHZWZmFc2FyszMKpoLlZmZVTQXKjMzq2guVGZmVtH+P55hM9FPKDoqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Importance\n",
    "importance = pd.DataFrame({\"Importance\": gbm_tuned_model.feature_importances_*100},\n",
    "                            index = X_train.columns)\n",
    "\n",
    "importance.sort_values(by = \"Importance\", axis= 0, ascending=True).plot(kind=\"barh\", color = \"orange\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.gca().legend = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolution of Tree-Based Algorithms and XGBoost Algorithm\n",
    "\n",
    "XGBoost is a decision-tree-based ensemble Machine Learning algorithm that uses a gradient boosting framework. In prediction problems involving unstructured data (images, text, etc.) artificial neural networks tend to outperform all other algorithms or frameworks. However, when it comes to small-to-medium structured/tabular data, decision tree based algorithms are considered best-in-class right now. \n",
    "\n",
    "![XGBoost](https://miro.medium.com/proxy/1*QJZ6W-Pck_W7RlIDwUIN9Q.jpeg)\n",
    "\n",
    "The algorithm differentiates itself in the following ways:\n",
    "\n",
    "- A wide range of applications: Can be used to solve regression, classification, ranking, and user-defined prediction problems.\n",
    "\n",
    "- Portability: Runs smoothly on Windows, Linux, and OS X.\n",
    "\n",
    "- Languages: Supports all major programming languages including C++, Python, R, Java, Scala, and Julia.\n",
    "\n",
    "- Cloud Integration: Supports AWS, Azure, and Yarn clusters and works well with Flink, Spark, and other ecosystems.\n",
    "\n",
    "Each step of the evolution of tree-based algorithms can be viewed as below.\n",
    "\n",
    "- **Decision Tree:** Every hiring manager has a set of criteria such as education level, number of years of experience, interview performance. A decision tree is analogous to a hiring manager interviewing candidates based on his or her own criteria.\n",
    "\n",
    "- **Bagging:** Now imagine instead of a single interviewer, now there is an interview panel where each interviewer has a vote. Bagging or bootstrap aggregating involves combining inputs from all interviewers for the final decision through a democratic voting process.\n",
    "\n",
    "- **Random Forest:** It is a bagging-based algorithm with a key difference wherein only a subset of features is selected at random. In other words, every interviewer will only test the interviewee on certain randomly selected qualifications (e.g. a technical interview for testing programming skills and a behavioral interview for evaluating non-technical skills).\n",
    "\n",
    "- **Boosting:** This is an alternative approach where each interviewer alters the evaluation criteria based on feedback from the previous interviewer. This ‘boosts’ the efficiency of the interview process by deploying a more dynamic evaluation process.\n",
    "\n",
    "- **Gradient Boosting:** A special case of boosting where errors are minimized by gradient descent algorithm e.g. the strategy consulting firms leverage by using case interviews to weed out less qualified candidates.\n",
    "\n",
    "- **XGBoost:** Think of XGBoost as gradient boosting on ‘steroids’ (well it is called ‘Extreme Gradient Boosting’ for a reason!). It is a perfect combination of software and hardware optimization techniques to yield superior results using less computing resources in the shortest amount of time.\n",
    "\n",
    "**Why does XGBoost perform so well?**\n",
    "\n",
    "**System Optimization:**\n",
    "\n",
    "\n",
    "- **Parallelization:** XGBoost approaches the process of sequential tree building using parallelized implementation. This is possible due to the interchangeable nature of loops used for building base learners; the outer loop that enumerates the leaf nodes of a tree, and the second inner loop that calculates the features. This nesting of loops limits parallelization because without completing the inner loop (more computationally demanding of the two), the outer loop cannot be started. Therefore, to improve run time, the order of loops is interchanged using initialization through a global scan of all instances and sorting using parallel threads. This switch improves algorithmic performance by offsetting any parallelization overheads in computation.\n",
    "\n",
    "\n",
    "- **Tree Pruning:** The stopping criterion for tree splitting within GBM framework is greedy in nature and depends on the negative loss criterion at the point of split. XGBoost uses ‘max_depth’ parameter as specified instead of criterion first, and starts pruning trees backward. This ‘depth-first’ approach improves computational performance significantly.\n",
    "\n",
    "- **Hardware Optimization:** This algorithm has been designed to make efficient use of hardware resources. This is accomplished by cache awareness by allocating internal buffers in each thread to store gradient statistics. Further enhancements such as ‘out-of-core’ computing optimize available disk space while handling big data-frames that do not fit into memory.\n",
    "\n",
    "**Algorithmic Enhancements:**\n",
    "\n",
    "- **Regularization:** It penalizes more complex models through both LASSO (L1) and Ridge (L2) regularization to prevent overfitting.\n",
    "\n",
    "- **Sparsity Awareness:** XGBoost naturally admits sparse features for inputs by automatically ‘learning’ best missing value depending on training loss and handles different types of sparsity patterns in the data more efficiently.\n",
    "\n",
    "- **Weighted Quantile Sketch:** XGBoost employs the distributed weighted Quantile Sketch algorithm to effectively find the optimal split points among weighted datasets.\n",
    "\n",
    "- **Cross-validation:** The algorithm comes with built-in cross-validation method at each iteration, taking away the need to explicitly program this search and to specify the exact number of boosting iterations required in a single run.\n",
    "\n",
    "![XGBoost_2](https://miro.medium.com/proxy/1*FLshv-wVDfu-i54OqvZdHg.png)\n",
    "\n",
    "\n",
    "**Source:**\n",
    "\n",
    "[Towards Data Science](https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d#:~:text=XGBoost%20is%20a%20decision%2Dtree,all%20other%20algorithms%20or%20frameworks.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:27:47.587878Z",
     "iopub.status.busy": "2021-10-16T17:27:47.587626Z",
     "iopub.status.idle": "2021-10-16T17:27:47.611142Z",
     "shell.execute_reply": "2021-10-16T17:27:47.610479Z",
     "shell.execute_reply.started": "2021-10-16T17:27:47.587844Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model & Prediction\n",
    "\n",
    "df = pd.read_csv(\"../input/hitters-baseball-data/Hitters.csv\")\n",
    "df = df.dropna()\n",
    "# Transforming categorical data to dummy data\n",
    "dms = pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])\n",
    "y = df[\"Salary\"]\n",
    "X_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis= 1).astype(\"float64\")\n",
    "X = pd.concat([X_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "y,\n",
    "test_size = 0.2,\n",
    "random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:27:47.612606Z",
     "iopub.status.busy": "2021-10-16T17:27:47.612356Z",
     "iopub.status.idle": "2021-10-16T17:27:55.954306Z",
     "shell.execute_reply": "2021-10-16T17:27:55.953451Z",
     "shell.execute_reply.started": "2021-10-16T17:27:47.612558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (1.4.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.7.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.19.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:27:55.958266Z",
     "iopub.status.busy": "2021-10-16T17:27:55.958024Z",
     "iopub.status.idle": "2021-10-16T17:27:57.378702Z",
     "shell.execute_reply": "2021-10-16T17:27:57.378032Z",
     "shell.execute_reply.started": "2021-10-16T17:27:55.958238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298.061591603747"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor().fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:27:57.380238Z",
     "iopub.status.busy": "2021-10-16T17:27:57.379977Z",
     "iopub.status.idle": "2021-10-16T17:27:57.390478Z",
     "shell.execute_reply": "2021-10-16T17:27:57.389558Z",
     "shell.execute_reply.started": "2021-10-16T17:27:57.380201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=2, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T17:27:57.392294Z",
     "iopub.status.busy": "2021-10-16T17:27:57.391942Z",
     "iopub.status.idle": "2021-10-16T17:27:57.397737Z",
     "shell.execute_reply": "2021-10-16T17:27:57.396743Z",
     "shell.execute_reply.started": "2021-10-16T17:27:57.392241Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_params = {\"learning_rate\": [0.1,0.01,0.5],\n",
    "\"max_depth\": [2,3,4,5,8],\n",
    "\"n_estimators\": [100,200,500,1000],\n",
    "\"colsample_bytree\": [0.4,0.7,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-10-16T17:27:57.399814Z",
     "iopub.status.busy": "2021-10-16T17:27:57.399456Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 180 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   35.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8, total=   0.9s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8, total=   0.9s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8, total=   0.9s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1, total=   3.0s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1, total=   3.0s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5, total=   1.7s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5, total=   2.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5, total=   1.8s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8, total=   2.4s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8, total=   2.6s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8, total=   1.7s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=100, total=   8.2s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=100, total=   0.3s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=100, total=   0.1s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=100, total=   0.3s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=200 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=200, total=   0.3s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=200 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=200, total=   0.2s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=200 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=200, total=   2.2s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=200 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=200, total=   6.5s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=500, total=   9.6s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=500, total=   0.5s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=500, total=   1.0s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=500, total=   0.5s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=500, total=   0.6s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=1000 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=1000, total=   0.8s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=1000 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=1000, total=   1.1s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=1000 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=1000, total=   1.0s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=1000 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=1000, total=   2.0s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=1000 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=1000, total=   0.9s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=100, total=   0.1s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=100, total=   0.2s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=100, total=   0.2s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=100, total=   0.1s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=100, total=   0.2s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=100, total=   0.1s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=100, total=   0.1s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=100, total=   0.1s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=100, total=   2.7s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=200 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=200, total=   0.5s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=200 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=200, total=   0.4s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=200 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=200, total=   0.5s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=200 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=200, total=   0.4s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=200 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=200, total=   0.4s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=500, total=   0.8s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=500, total=   9.1s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=500, total=   0.6s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=500, total=   0.6s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=500, total=   0.4s\n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1, total=   3.2s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1, total=   2.9s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5, total=   2.5s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5, total=   1.8s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8, total=   2.9s\n",
      "[CV] learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8 \n",
      "[CV]  learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8, total=   2.5s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=100, total=   8.0s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=100, total=   0.1s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=100, total=   0.1s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=100, total=   0.1s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=100, total=   0.1s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=100, total=   0.3s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=200 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=200, total=   0.3s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=200 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=200, total=   0.3s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=200 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=200, total=   0.1s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=200 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=200, total=   1.8s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=200 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=200, total=   0.5s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=200 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=200, total=  14.8s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=500, total=   1.4s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=500, total=   0.5s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=500, total=   1.2s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=500, total=   0.6s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=500, total=   2.0s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=1000 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=1000, total=   1.0s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=1000 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=1000, total=   1.0s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=1000 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=1000, total=   1.1s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=1000 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=1000, total=   0.9s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=1000 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=2, n_estimators=1000, total=   1.2s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=100, total=   2.4s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=200 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=200, total=   0.7s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=200 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=200, total=   0.4s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=200 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=200, total=   0.4s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=200 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=200, total=   0.2s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=200 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=200, total=   0.3s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=500, total=   1.0s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=500, total=   9.2s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=500, total=   0.6s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=500, total=   0.6s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=500, total=   0.4s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=1000 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=1000, total=   1.1s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=1000 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=1000, total=   1.1s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=1000 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=1000, total=   1.3s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=1000 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=1000, total=   1.3s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=1000 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=3, n_estimators=1000, total=   1.1s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=4, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=4, n_estimators=100, total=   2.1s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=4, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=4, n_estimators=100, total=  10.6s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=4, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=4, n_estimators=100, total=   0.9s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=4, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.4, learning_rate=0.1, max_depth=4, n_estimators=100, total=   0.2s\n",
      "[CV] colsample_bytree=0.4, learning_rate=0.1, max_depth=4, n_estimators=100 "
     ]
    }
   ],
   "source": [
    "xgb_cv_model = GridSearchCV(xgb, xgb_params, verbose=2, cv=10, n_jobs=-1).fit(X_train, y_train)\n",
    "xgb_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM\n",
    "\n",
    "Light GBM is a gradient boosting framework that uses tree based learning algorithm.\n",
    "\n",
    "**How it differs from other tree based algorithm?**\n",
    "\n",
    "Light GBM grows tree vertically while other algorithm grows trees horizontally meaning that Light GBM grows tree leaf-wise while other algorithm grows level-wise. It will choose the leaf with max delta loss to grow. When growing the same leaf, Leaf-wise algorithm can reduce more loss than a level-wise algorithm.\n",
    "\n",
    "Below diagrams explain the implementation of LightGBM and other boosting algorithms.\n",
    "\n",
    "Light GBM & Other Boosting Algorithms\n",
    "\n",
    "![Light GBM](https://www.yildirimmehmet.com/wp-content/uploads/2021/03/13.png)\n",
    "\n",
    "The size of data is increasing day by day and it is becoming difficult for traditional data science algorithms to give faster results. Light GBM is prefixed as ‘Light’ because of its high speed. Light GBM can handle the large size of data and takes lower memory to run. Another reason of why Light GBM is popular is because it focuses on accuracy of results. LGBM also supports GPU learning and thus data scientists are widely using LGBM for data science application development.\n",
    "\n",
    "\n",
    "**Can we use Light GBM everywhere?**\n",
    "\n",
    "No, it is not advisable to use LGBM on small datasets. Light GBM is sensitive to overfitting and can easily overfit small data. Their is no threshold on the number of rows but my experience suggests me to use it only for data with 10,000+ rows\n",
    "\n",
    "**Source:**\n",
    "\n",
    "[Light GBM Documentation](https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html#macos)\n",
    "\n",
    "[Medium](https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T20:11:04.474170Z",
     "iopub.status.busy": "2021-10-16T20:11:04.473446Z",
     "iopub.status.idle": "2021-10-16T20:11:04.520571Z",
     "shell.execute_reply": "2021-10-16T20:11:04.519882Z",
     "shell.execute_reply.started": "2021-10-16T20:11:04.474130Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model & Prediction\n",
    "\n",
    "df = pd.read_csv(\"../input/hitters-baseball-data/Hitters.csv\")\n",
    "df = df.dropna()\n",
    "# Transforming categorical data to dummy data\n",
    "dms = pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])\n",
    "y = df[\"Salary\"]\n",
    "X_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis= 1).astype(\"float64\")\n",
    "X = pd.concat([X_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "y,\n",
    "test_size = 0.2,\n",
    "random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T20:11:06.619520Z",
     "iopub.status.busy": "2021-10-16T20:11:06.619260Z",
     "iopub.status.idle": "2021-10-16T20:11:14.866112Z",
     "shell.execute_reply": "2021-10-16T20:11:14.865288Z",
     "shell.execute_reply.started": "2021-10-16T20:11:06.619490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/conda/lib/python3.7/site-packages (3.2.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from lightgbm) (1.7.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from lightgbm) (0.37.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from lightgbm) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /opt/conda/lib/python3.7/site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T20:11:14.868497Z",
     "iopub.status.busy": "2021-10-16T20:11:14.868217Z",
     "iopub.status.idle": "2021-10-16T20:11:17.092889Z",
     "shell.execute_reply": "2021-10-16T20:11:17.092144Z",
     "shell.execute_reply.started": "2021-10-16T20:11:14.868460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "353.89197703728786"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "lgb = LGBMRegressor().fit(X_train, y_train)\n",
    "lgb.get_params\n",
    "y_pred = lgb.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-10-16T20:11:31.011178Z",
     "iopub.status.busy": "2021-10-16T20:11:31.010887Z",
     "iopub.status.idle": "2021-10-16T20:11:43.709647Z",
     "shell.execute_reply": "2021-10-16T20:11:43.709020Z",
     "shell.execute_reply.started": "2021-10-16T20:11:31.011147Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:    5.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.1, max_depth=2, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.1, max_depth=2, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.1, max_depth=2, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.1, max_depth=2, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.1, max_depth=2, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.1, max_depth=2, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.1, max_depth=3, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.1, max_depth=3, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.1, max_depth=3, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.1, max_depth=3, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.1, max_depth=3, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.1, max_depth=3, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.1, max_depth=3, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.1, max_depth=3, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.1, max_depth=5, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.1, max_depth=5, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.1, max_depth=5, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.1, max_depth=5, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.1, max_depth=5, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.1, max_depth=5, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.1, max_depth=5, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.1, max_depth=5, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.1, max_depth=5, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=500, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=500, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, total=   0.1s[CV] learning_rate=0.1, max_depth=2, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.1, max_depth=2, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.1, max_depth=2, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.1, max_depth=2, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.1, max_depth=2, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.1, max_depth=2, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.1, max_depth=2, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.1, max_depth=2, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.1, max_depth=2, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.1, max_depth=2, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.1, max_depth=3, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.1, max_depth=3, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.1, max_depth=3, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.1, max_depth=3, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.1, max_depth=3, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.1, max_depth=3, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.1, max_depth=3, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.1, max_depth=5, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.1, max_depth=5, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.1, max_depth=5, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.1, max_depth=5, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.1, max_depth=5, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.1, max_depth=5, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=500, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=500, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=500, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=500, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=500 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=500 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=500 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.5, max_depth=2, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.5, max_depth=2, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.5, max_depth=2, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.5, max_depth=2, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.5, max_depth=2, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.5, max_depth=3, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.5, max_depth=3, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.5, max_depth=3, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.5, max_depth=3, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.5, max_depth=3, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.5, max_depth=3, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.5, max_depth=3, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.5, max_depth=5, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.5, max_depth=5, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.5, max_depth=5, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.5, max_depth=5, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.5, max_depth=5, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.5, max_depth=5, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.5, max_depth=5, n_estimators=500, total=   0.2s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.5, max_depth=5, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=2, n_estimators=100 ..................\n",
      "[CV] ... learning_rate=1, max_depth=2, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=2, n_estimators=100 ..................\n",
      "[CV] ... learning_rate=1, max_depth=2, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=2, n_estimators=100 ..................\n",
      "[CV] ... learning_rate=1, max_depth=2, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=2, n_estimators=100 ..................\n",
      "[CV] ... learning_rate=1, max_depth=2, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=2, n_estimators=100 ..................\n",
      "[CV] ... learning_rate=1, max_depth=2, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=2, n_estimators=200 ..................\n",
      "[CV] ... learning_rate=1, max_depth=2, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=2, n_estimators=200 ..................\n",
      "[CV] ... learning_rate=1, max_depth=2, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=2, n_estimators=200 ..................\n",
      "[CV] ... learning_rate=1, max_depth=2, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=2, n_estimators=500 ..................\n",
      "[CV] ... learning_rate=1, max_depth=2, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=2, n_estimators=500 ..................\n",
      "[CV] ... learning_rate=1, max_depth=2, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=3, n_estimators=100 ..................\n",
      "[CV] ... learning_rate=1, max_depth=3, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=3, n_estimators=100 ..................\n",
      "[CV] ... learning_rate=1, max_depth=3, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=3, n_estimators=100 ..................\n",
      "[CV] ... learning_rate=1, max_depth=3, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=3, n_estimators=100 ..................\n",
      "[CV] ... learning_rate=1, max_depth=3, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=3, n_estimators=200 ..................\n",
      "[CV] ... learning_rate=1, max_depth=3, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=3, n_estimators=200 ..................\n",
      "[CV] ... learning_rate=1, max_depth=3, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=3, n_estimators=500 ..................\n",
      "[CV] ... learning_rate=1, max_depth=3, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=3, n_estimators=500 ..................\n",
      "[CV] ... learning_rate=1, max_depth=3, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=5, n_estimators=100 ..................\n",
      "[CV] ... learning_rate=1, max_depth=5, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=5, n_estimators=100 ..................\n",
      "[CV] ... learning_rate=1, max_depth=5, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=5, n_estimators=100 ..................\n",
      "[CV] ... learning_rate=1, max_depth=5, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=5, n_estimators=200 ..................\n",
      "[CV] ... learning_rate=1, max_depth=5, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=5, n_estimators=200 ..................\n",
      "[CV] ... learning_rate=1, max_depth=5, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=5, n_estimators=200 ..................\n",
      "[CV] ... learning_rate=1, max_depth=5, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=5, n_estimators=500 ..................\n",
      "[CV] ... learning_rate=1, max_depth=5, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=5, n_estimators=500 ..................\n",
      "[CV] ... learning_rate=1, max_depth=5, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=10, n_estimators=100 .................\n",
      "[CV] .. learning_rate=1, max_depth=10, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=10, n_estimators=100 .................\n",
      "[CV] .. learning_rate=1, max_depth=10, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=500 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=500, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=500 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.5, max_depth=2, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.5, max_depth=2, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.5, max_depth=2, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.5, max_depth=2, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.5, max_depth=2, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.5, max_depth=2, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.5, max_depth=2, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.5, max_depth=2, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.5, max_depth=2, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.5, max_depth=2, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.5, max_depth=3, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.5, max_depth=3, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.5, max_depth=3, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.5, max_depth=3, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.5, max_depth=3, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.5, max_depth=3, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.5, max_depth=3, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.5, max_depth=3, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=100 ................\n",
      "[CV] . learning_rate=0.5, max_depth=5, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.5, max_depth=5, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.5, max_depth=5, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=200 ................\n",
      "[CV] . learning_rate=0.5, max_depth=5, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.5, max_depth=5, n_estimators=500, total=   0.2s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.5, max_depth=5, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=500 ................\n",
      "[CV] . learning_rate=0.5, max_depth=5, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=2, n_estimators=200 ..................\n",
      "[CV] ... learning_rate=1, max_depth=2, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=2, n_estimators=200 ..................\n",
      "[CV] ... learning_rate=1, max_depth=2, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=2, n_estimators=500 ..................\n",
      "[CV] ... learning_rate=1, max_depth=2, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=2, n_estimators=500 ..................\n",
      "[CV] ... learning_rate=1, max_depth=2, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=2, n_estimators=500 ..................\n",
      "[CV] ... learning_rate=1, max_depth=2, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=3, n_estimators=100 ..................\n",
      "[CV] ... learning_rate=1, max_depth=3, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=3, n_estimators=200 ..................\n",
      "[CV] ... learning_rate=1, max_depth=3, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=3, n_estimators=200 ..................\n",
      "[CV] ... learning_rate=1, max_depth=3, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=3, n_estimators=200 ..................\n",
      "[CV] ... learning_rate=1, max_depth=3, n_estimators=200, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=3, n_estimators=500 ..................\n",
      "[CV] ... learning_rate=1, max_depth=3, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=3, n_estimators=500 ..................\n",
      "[CV] ... learning_rate=1, max_depth=3, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=3, n_estimators=500 ..................\n",
      "[CV] ... learning_rate=1, max_depth=3, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=5, n_estimators=100 ..................\n",
      "[CV] ... learning_rate=1, max_depth=5, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=5, n_estimators=100 ..................\n",
      "[CV] ... learning_rate=1, max_depth=5, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=5, n_estimators=200 ..................\n",
      "[CV] ... learning_rate=1, max_depth=5, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=5, n_estimators=200 ..................\n",
      "[CV] ... learning_rate=1, max_depth=5, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=5, n_estimators=500 ..................\n",
      "[CV] ... learning_rate=1, max_depth=5, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=5, n_estimators=500 ..................\n",
      "[CV] ... learning_rate=1, max_depth=5, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=5, n_estimators=500 ..................\n",
      "[CV] ... learning_rate=1, max_depth=5, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=10, n_estimators=100 .................\n",
      "[CV] .. learning_rate=1, max_depth=10, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=10, n_estimators=200 .................\n",
      "[CV] .. learning_rate=1, max_depth=10, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=10, n_estimators=200 .................\n",
      "[CV] .. learning_rate=1, max_depth=10, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=10, n_estimators=200 .................\n",
      "[CV] .. learning_rate=1, max_depth=10, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=10, n_estimators=500 .................\n",
      "[CV] .. learning_rate=1, max_depth=10, n_estimators=500, total=   0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:   12.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Tuning\n",
    "lgb_params = {\"learning_rate\": [0.1, 0.01, 0.5, 1],\n",
    "\"n_estimators\": [100,200,500],\n",
    "\"max_depth\": [2,3,5,10]}\n",
    "\n",
    "lgb_cv_model = GridSearchCV(lgb, lgb_params, \n",
    "                            cv=5, verbose=2, \n",
    "                            n_jobs= -1).fit(X_train, y_train)\n",
    "lgb_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T20:11:43.714659Z",
     "iopub.status.busy": "2021-10-16T20:11:43.713139Z",
     "iopub.status.idle": "2021-10-16T20:11:43.829132Z",
     "shell.execute_reply": "2021-10-16T20:11:43.828574Z",
     "shell.execute_reply.started": "2021-10-16T20:11:43.714624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361.7822472211918"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] learning_rate=1, max_depth=10, n_estimators=100 .................\n",
      "[CV] .. learning_rate=1, max_depth=10, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=10, n_estimators=100 .................\n",
      "[CV] .. learning_rate=1, max_depth=10, n_estimators=100, total=   0.0s\n",
      "[CV] learning_rate=1, max_depth=10, n_estimators=200 .................\n",
      "[CV] .. learning_rate=1, max_depth=10, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=10, n_estimators=200 .................\n",
      "[CV] .. learning_rate=1, max_depth=10, n_estimators=200, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=10, n_estimators=500 .................\n",
      "[CV] .. learning_rate=1, max_depth=10, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=10, n_estimators=500 .................\n",
      "[CV] .. learning_rate=1, max_depth=10, n_estimators=500, total=   0.1s\n",
      "\n",
      "[CV] learning_rate=1, max_depth=10, n_estimators=500 .................\n",
      "[CV] .. learning_rate=1, max_depth=10, n_estimators=500, total=   0.1s\n",
      "[CV] learning_rate=1, max_depth=10, n_estimators=500 .................\n",
      "[CV] .. learning_rate=1, max_depth=10, n_estimators=500, total=   0.1s\n"
     ]
    }
   ],
   "source": [
    "lgbm_tuned_model = LGBMRegressor(learning_rate=0.01, \n",
    "                                 max_depth=5, \n",
    "                                 n_estimators=500).fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgbm_tuned_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
